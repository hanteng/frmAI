---
tags:
 - 非完全資訊博弈
 - 多智能體博弈
 - 推理與欺騙
 - 自然語言處理
 - 大語言模型
 - 納許均衡
 - 強化學習
---
# 🐺🧑‍🌾 狼人殺 AI🏆 {#sec-werewolf-ai}

`狼人殺 AI` （Werewolf AI，日語_Jinrō Game_）代表著人工智慧在**非完全資訊博弈**領域的一大挑戰與突破。這類 AI 專案成功在《狼人殺》或《Mafia》 這類遊戲中，實現了基於**推理**、**溝通**與**欺騙**的複雜博弈。狼人殺 AI 的成就，標誌著 AI 在處理**自然語言溝通**和**社會動態博弈**中的重要里程碑，更見證了 **[大語言模型](02-07-large_language_models.zh-hant)** 能介入人類社會 **[語言賽局](01-07-Language_Games.zh-hant)** 的能力。

## 🏆 博弈挑戰

《狼人殺》是一款典型的**多人非完全資訊博弈**遊戲，是 **[語言賽局](01-07-Language_Games.zh-hant)** 的一種。遊戲中，所有決策都必須基於對話、邏輯推理與觀察，**資訊不完全**是其最大的挑戰。具體挑戰有：

- **極端資訊不完全**：玩家僅知道自己的身份和極少數資訊，必須在資訊不對稱的環境中判斷誰是敵友；
- **自然語言溝通**：AI 必須理解複雜的人類語言，包括言外之意、潛在的矛盾、以及隱藏的謊言；
- **推理與欺騙的耦合**：AI 不僅要根據邏輯推理出其他玩家的身份（**推論**），還必須學會**說謊**或**掩飾**自己的真實意圖（**欺騙**）；
- **多智能體社會動態**：AI 必須在多個智能體之間處理複雜的**信任、聯盟、背叛**等社會動態。

## 📜 博弈歷史

狼人殺 AI 的研究始於 2010 年代初，旨在測試 AI 在處理複雜社會博弈中的能力，並隨著 LLM 的出現獲得重大突破：

- **2017年**：一個由日本科學家開發的 AI 狼人，在與四位人類玩家的遊戲中，成功在第一晚就贏得勝利，展示了基於邏輯推理的 AI 在簡化規則下的潛力。
- **2021年**：卡內基美隆大學等團隊開發的 AI **“Werewolf AI”**，在多輪遊戲中表現出與人類玩家相當的推理與欺騙能力。
- **當代**：透過結合 **[大語言模型](02-07-large_language_models.zh-hant)**，現代狼人殺 AI 在語言表達和說服力方面大幅提升，使其能更自然地融入人類博弈。

**這些 AI 項目證明了 AI 在語言博弈和信任推論方面具備了強大的潛力。**

## ✅ 克服難點方式

要讓 AI 玩狼人殺，需要結合 **[邏輯推理](03-01-formal_logic.zh-hant.md)** 與 **[深度學習](04-03-neural_networks.zh-hant.md)**，讓 AI 不僅會算，更會「演」。

1.  **語言理解與情勢分析 (NLP)**：
    * AI 透過 **自然語言處理 (NLP)** 技術，將每個玩家的發言轉化為可分析的數據。它評估發言的**可信度**、邏輯連貫性，並分析矛盾點，從而動態調整對其他玩家身份的**機率推論**。
2.  **強化學習與納許均衡策略**：
    * AI 會與自己進行數百萬場的模擬對戰（**自我博弈**），從經驗中學習並應用博弈論概念，如**納許均衡**（近似最佳策略）。
    * **穩健策略**：AI 學習如何在資訊極度不對稱和高隨機性的環境中，發展出**穩健**且**難以被預測**的策略，包括決定**何時說謊、如何掩飾身份**以及**如何與隊友合作**。

## 🔑 關鍵技術

狼人殺 AI 的核心在於 **將非結構化的自然語言數據結構化**，並利用強化學習和 LLM 進行策略和表達的優化。

* **身份機率推論模型**：利用貝氏網絡或深度學習模型，根據每個玩家的發言、投票和行動歷史，實時更新其身份的**機率分佈**，這是所有決策的基礎。
* **納許均衡與子賽局分析**：使用強化學習來逼近遊戲在特定階段（子賽局）的**近似納許均衡**策略，確保 AI 的行為在理論上具有穩健性。
* **LLM 融入與角色扮演**：結合 **[大語言模型](02-07-large_language_models.zh-hant.md)** 來生成流暢、自然且符合**角色設定**（如狼人、預言家）的對話。
* **提示與脈絡工程**：
    * **[提示工程](10-03-prompt_engineering.zh-hant.md)**：用於定義 LLM 的身份、目標與個性，確保語言表達服務於遊戲策略。
    * **[脈絡工程](10-05-context_engineering.zh-hant.md)**：用於提供 LLM 當前遊戲狀態與所有玩家歷史發言的完整資訊，確保其回應具有情境連貫性。

## 💡 AI 應用啟發

狼人殺 AI 的案例，展示了 AI 不僅能在數據明確的環境中獲勝，也能在充滿不確定性、資訊不對稱與社會動態的複雜環境中展現智能。

- **🎯 問題意識**：適用於 **需要處理口頭溝通、不確定性與欺騙** 的任務，例如談判、法律諮詢、網路安全、或複雜的商業協商。
- **🗺️ 建構資源**：能將 **自然語言對話** 與**社會動態**轉化為可供 AI 分析的**結構化數據**。
- **⚡ 智能加值**：AI 能夠學會**多方策略**，並在**資訊不對稱**的環境中做出最佳決策，展現出高階的**推理**和**社會感知**能力。
- **🏭 佈署條件**：適合在**人機協作**或**多智能體**的虛擬環境中部署，並可逐步擴展至需要自然語言理解和社會判斷的現實應用。

### 對「博弈派」AI 的核心貢獻

狼人殺 AI 的成就，為 AI 處理複雜的社會動態、語言與不確定性，開闢了新的路徑。

* **語言與推理的整合**：首次將**自然語言處理**、**概率推論**與**博弈策略**深度結合，證明 AI 能在非結構化溝通中進行複雜的策略對抗。
* **欺騙策略的演化**：AI 成功演化出**主動欺騙**和**誤導對手**的策略，突破了過去博弈 AI 僅限於「理性最優」決策的局限，進入了「社會心理戰」領域。
* **非完全資訊中的 LLM 應用**：展示了如何利用 LLM 的強大語言生成能力，服務於博弈中的**戰術目標**（如說服、掩飾、質疑），而非僅僅用於內容生成。

這類研究的後續發展，例如 **Meta 的 [CICERO](https://ai.meta.com/research/cicero/diplomacy/) 專案** 在需要**自然語言外交**的《**Diplomacy**》遊戲上的成功，進一步證明了語言在複雜多智能體博弈中的決定性作用。

總而言之，狼人殺 AI 為 AI 介入充滿社會、語言與欺騙元素的真實世界複雜賽局，奠定了理論與實踐基礎。

### 對「具身派」AI 的啟發

狼人殺 AI 的經驗，為具身 AI 在不可預測、充滿社會互動的真實世界中運行，提供了關鍵的決策和感知模型。

* **人機互動與信任**：狼人殺 AI 必須建立和破壞玩家之間的信任。這對具身 AI 在**人機協作**中，如何設計其溝通策略以贏得人類信任或實施特定目標（如勸說人類進行某項操作）有重要啟發。
* **社會推理及心理操弄的「嵌入層」**：遊戲核心在於理解和推斷其他代理人的**潛在意圖和隱藏身份**。這證明了 AI 有能力處理人類社會互動中**不可見的、深層次的「社會推理嵌入層」**，對於具身 AI 在**人群中**運行、預測人類行為、並推斷用戶意圖以確保安全和有效協作的需求至關重要。

最終，狼人殺 AI 證明了機器有能力處理高階的社會推理及心理操弄，這是具身 AI 邁向更複雜、以人為中心的環境所必備的能力。

***

## 👉 下一部分

在理解 **[狼人殺 AI](07-06-werewolf_ai.zh-hant.md)** 在推理與欺騙博弈中的啟發後，接下來探討 **[複雜戰略模擬](07-07-complex_strategic_simulation.zh-hant.md)** 在大型策略決策中的啟發。