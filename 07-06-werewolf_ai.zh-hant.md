---
tags:
  - 非完全資訊博弈
  - 多智能體博弈
  - 推理與欺騙
  - 自然語言處理
  - 大語言模型
  - 納許均衡
  - 強化學習
---
# 🐺🧑‍🌾 狼人殺 AI🏆 {#sec-werewolf-ai}

`狼人殺 AI` （Werewolf AI，日語_Jinrō Game_）代表著人工智慧在**非完全資訊博弈**領域的一大挑戰與突破。這類 AI 專案，例如由日本與加拿大研究團隊共同開發的 AI 玩家，成功在《狼人殺》或《Mafia》 這類遊戲中，實現了基於**推理**、**溝通**與**欺騙**的複雜博弈。狼人殺 AI 的成就，標誌著 AI 在處理**自然語言溝通**和**社會動態博弈**中的重要里程碑，更見證了 **[大語言模型](02-07-large_language_models.zh-hant)** 能介入人類社會 **[語言賽局](01-07-Language_Games.zh-hant)** 的能力，如採用 [提示工程](10-03-prompt_engineering.zh-hant)及[脈絡工程](10-05-context_engineering.zh-hant)去形塑互動角色。

## 🐺🧑‍🌾 博弈挑戰與歷史

《狼人殺》是一款典型的**多人非完全資訊博弈**遊戲，可以算是 **[語言賽局](01-07-Language_Games.zh-hant)** 的一種。遊戲中，玩家身份分為**狼人**和**平民**兩大陣營，目標分別是消滅所有平民或所有狼人。由於身份資訊對玩家是隱藏的，所有決策都必須基於對話、邏輯推理與觀察。

### 🏆 博弈挑戰

《狼人殺》的具體挑戰有：

- **非完全資訊**：玩家僅知道自己的身份，必須在資訊不對稱的環境中做出判斷；
    
- **自然語言溝通**：AI 必須理解複雜的人類語言，包括言外之意、矛盾、以及隱藏的謊言；
    
- **推理與欺騙**：AI 不僅要根據對話邏輯推理出其他玩家的身份，還必須學會**說謊**或**掩飾**自己的真實意圖；
    
- **多智能體社會動態**：AI 必須在多個智能體之間進行複雜的互動，處理聯盟、背叛與合作等動態。

### 📜 博弈歷史

狼人殺 AI 的研究始於 2010 年代初，主要由學術界推動，旨在測試 AI 在處理複雜社會博弈中的能力：

- 2017年，一個由日本科學家開發的 AI 狼人，在與四位人類玩家的遊戲中，成功在第一晚就贏得勝利，這被視為一次重大突破。
    
- 2021年，卡內基美隆大學等團隊開發的 AI **“Werewolf AI”**，在多輪遊戲中表現出與人類玩家相當的推理與欺騙能力。
    
- 這些 AI 項目雖然還未達到頂級人類玩家的水平，但已證明 AI 在**語言博弈**和**信任推論**方面具備了強大的潛力。
    

如下段所詳述，狼人殺 AI 主要透過結合**邏輯推理**與**深度學習**，來應對自然語言和複雜博弈的挑戰。


### ✅ 克服難點方式 (How Werewolf AI Overcomes Challenges)

要讓 AI 玩狼人殺，光靠死板的規則和邏輯是不夠的。研究人員結合了兩種主要技術，讓 AI 不只會算，更會「演」。主要利用 **[邏輯推理](03-01-formal_logic.zh-hant.md)** 與 **[深度學習](04-03-neural_networks.zh-hant.md)**，分以下2學習階段：

1. **語言理解** 與 **情勢分析**：AI 必須先聽懂大家在說什麼，才能做出判斷
	* 這部分主要靠 **自然語言處理**（NLP）技術。
	* AI 會把每個玩家的發言，轉化成數學上可以分析的數據。它不只是分析詞彙，更重要的是會評估發言的「可信度」**。
	* 例如，如果某個玩家的發言前後矛盾，AI 會馬上降低他身份為平民的機率。這就像福爾摩斯一樣，從每個人的話裡找線索。    
2. **策略學習與應用**：光有線索還不夠，AI 還要學會如何利用線索進行模擬對戰
	* 這部分是**強化學習**發揮作用的地方，AI 會跟自己進行數百萬場的模擬對戰。從這些經驗中，AI 會學習並應用博弈論概念，叫**納許均衡**，來發展出自己的贏家策略
	* 簡單來說，就是一種「誰都無法單獨改變策略來獲利」的穩定狀態。因為狼人殺的變數太多，AI 無法計算出完美的納許均衡，所以它會：
	    - **分析小賽局**：把複雜的遊戲切成一個個的小情境，例如「當只剩下三個人時，我該怎麼發言？」然後找出每個小情境中的最佳應對方式。
		- **學習應變策略**：AI 的目標不是只贏一次，而是要發展出「**穩健**」的策略。就算對手的策略改變了，AI 也能夠穩定地獲勝。
		- **欺騙與合作**：最終學會如何在資訊不對稱的環境中，決定何時說謊、如何隱藏身份以及如何與隊友合作。

透過以上技術，狼人殺 AI 不僅能理解遊戲中的複雜對話，還能發展出靈活且難以捉摸的戰術，這也是它能和人類高手匹敵的關鍵，使 AI 成為一個難以被預測和擊敗的對手。

## 💡 AI 應用啟發

狼人殺 AI 的案例，展示了 AI 不僅能在數據明確的環境中獲勝，也能在充滿不確定性、資訊不對稱與社會動態的複雜環境中展現智能。

此案例對 AI 應用有以下啟發：

- **🎯 問題意識**：適用於 **需要處理口頭溝通、不確定性與欺騙** 的任務，例如談判、法律諮詢或網路安全。
    
- **🗺️ 建構資源**：能將 **自然語言對話** 與**社會動態**轉化為可供 AI 分析的**結構化數據**。
    
- **⚡ 智能加值**：AI 能夠學會**多方策略**，並在**資訊不對稱**的環境中做出最佳決策。
    
- **✨ LLM入語言賽局**： **[大語言模型](02-07-large_language_models.zh-hant.md)** 的加入，讓 AI 的語言表達能力大幅提升，能生成更自然、更具說服力的發言，甚至主動發起謊言或質疑，進而影響遊戲進程。
    
- **⚡️ 提示與脈絡工程**：為了讓 LLM 扮演好特定社會角色（如狼人、預言家），可以利用精準的 **[提示工程](10-03-prompt_engineering.zh-hant.md)** 來定義其身份、目標與個性。同時，**[脈絡工程](10-05-context_engineering.zh-hant.md)** 則用於提供當前遊戲狀態與所有玩家歷史發言的完整資訊，確保 LLM 的回應符合情境且連貫。
    
- **🏭 佈署條件**：適合在**人機協作**或**多智能體**的虛擬環境中部署，並可逐步擴展至需要自然語言理解和社會判斷的現實應用。

## 👉 下一部分

在理解 **[狼人殺 AI](https://www.google.com/search?q=07-06-werewolf_ai.zh-hant.md)** 在推理與欺騙博弈中的啟發後，接下來探討 **[複雜戰略模擬](https://www.google.com/search?q=07-07-battlefield_simulation.zh-hant.md)** 在大型策略決策中的啟發。