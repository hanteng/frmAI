---
tags:
- 自主性
- 目標導向
- 環境感知
---
# ☸智能體導向🤖 {#sec-oriented-agent}

`智能體導向 AI`（Agent-oriented AI）強調以 **自主性、目標導向與環境感知** 為核心，把 AI 系統視為能夠在**動態環境**中**持續感知、決策與行動**的「智能體」。此導向關注的不僅是 AI 是否能完成**單一任務**，而是其能否在複雜情境下**自主規劃、調整策略並持續追求長期目標**。此導向和 [情境主義](02----schools_paradigms.zh-hant.md)（Situated-ism）關係密切[@]。

`智能體導向 AI` 特別關注以下：

- **核心任務**：任務分解、策略規劃、情境感知、長期目標追蹤與自主決策。  
- **主要利害關係人**：研究者、系統架構師、產品經理、風險治理專家與最終使用者。  

因此，`智能體導向 AI` 常與 **多代理人系統**（Multi-agent Systems, MAS）、**自主決策架構**（Autonomous Decision-making Frameworks）及 **強化學習**（Reinforcement Learning, RL）的應用情境緊密相關，成為自動駕駛、智慧製造、金融交易與智慧城市等領域的關鍵支柱。

隨著數位環境日益複雜，`智能體導向 AI` 的「自主性」不僅意味著能在無人監督下完成任務，更包括在 **不確定性、資源限制與多重目標衝突** 的情境中，能動態調整行為並持續學習。這種導向要求 AI 不只是工具，而是能在環境中「行動」並與其他智能體或人類協作的存在。

在這樣的框架下，「**環境感知**」成為智能體導向的基礎：AI 必須能夠持續蒐集並解讀環境訊號，並將其轉化為決策依據。這一觀點在 **自主系統與多代理人研究** 的發展中尤為明顯：從自動駕駛車輛、智慧工廠到分散式能源網絡，`智能體導向` 形成一套以「感知（Perception）—決策（Decision-making）—行動（Action）—學習（Learning）」為核心的 **智能體閉環架構** [@russell2021]。


## 🤖🧭 定義：<br/>🎯目標導向的行動者

`智能體導向 AI` 建立在一組自主性與目標導向的原則之上，通常是實踐環境感知、策略規劃、持續學習與責任邊界的設計原則，這些原則使 AI 能在複雜環境中獨立運行[@russell2021]：

- 🎯 **目標導向**（Goal Orientation）：能夠設定、分解並持續追蹤長期與短期目標。  
- 👁️ **環境感知**（Environmental Perception）：持續蒐集並解讀環境訊號，形成決策依據。  
- 🧩 **策略規劃**（Strategic Planning）：在多重限制下動態調整行為，調整行動路徑。  
- 🔄 **持續學習**（Continuous Learning）：透過強化學習與回饋機制不斷優化行為策略。  
- ⚖️ **責任邊界**（Accountability Boundaries）：在自主行為中明確界定可控範圍與風險承擔。  
- 🤝 **協作互動**（Collaborative Interaction）：能與其他智能體或人類協作，形成多代理人系統。 

 `智能體導向 AI` 是一種「讓 AI 自己做主」的問題解決方式，這使其強大且具備彈性，但也因此帶來了最高的倫理和安全風險控制（Risk Control）的挑戰。

- 🔒 **[AI 對齊與控制問題](01-06-Alignment_Control_Problem.zh-hant.md)**：如何確保智能體的**長期目標**和**行為**決策始終符合人類價值與業務需求，成為核心難題。
- ⚠️ **不可預測性**：隨著智能體具備更多學習與規劃能力，其行為可能脫離設計者的預期，為監管和安全審核帶來極大困難。
- 🧭 **問責制與責任歸屬**等**治理需求**：需要結合監控、審計與合規框架，才能在享受閉環帶來的靈活性與生成力的同時，避免潛在的失控與濫用。

 因而和其它導向，特別是協作及治理概念的問題及解決方案，有所區別：

- ☸🤝 **協作導向**：協作導向偏重人本互動與採納體驗，智能體導向則偏重自主決策與長期目標；兩者需結合，確保自主行為能被人理解並融入協作流程。  
- ☸⚖️ **治理導向**：治理導向偏重制度化與合規檢核，智能體導向則偏重策略性與效率；兩者需結合，確保自主行為在制度框架下可被監督與問責。  

***

## ✨ 智能體導向特性

`智能體導向 AI` 具備「自主性、目標導向、環境感知」等核心特性，使其在 **自動駕駛、智慧製造、金融交易與智慧城市** 等領域展現無可替代的價值。以下是其主要正面與負面特徵：

#### 👍 正面特性

- 🎯 **自主性（Autonomy）**：能在無人監督下持續感知環境並執行決策，提升效率與即時性。  
- 🧭 **目標導向（Goal Orientation）**：具備長期與短期目標規劃能力，能動態調整策略以因應環境變化。  
- 👁️ **環境感知（Environmental Perception）**：持續蒐集並解讀感測器或數據輸入，形成決策依據。  
- 🧩 **策略規劃（Strategic Planning）**：能在多重限制下分解任務並規劃最佳行動路徑。  
- 🔄 **持續學習（Continuous Learning）**：透過強化學習與回饋機制不斷優化行為策略。  
- 🤝 **協作互動（Collaborative Interaction / Social Ability）**：能與其他智能體或人類協作，形成多代理人系統。  
- 🚀 **前瞻性（Proactiveness）**：不僅被動回應外部刺激，還能主動採取行動以達成目標。  

#### 👎 負面特性

- ⚠️ **不可預測性與責任模糊**（Unpredictability & Accountability Ambiguity）：高度自主可能導致行為難以完全預測或控制，且責任邊界不清。  
- 🔀 **目標衝突與價值對齊風險**（Goal Conflict & Alignment Risk）：在多代理系統中可能出現目標衝突，若缺乏價值對齊機制，可能導致偏差或不符合倫理的行為。  
- 🕵️ **透明度與可解釋性低**（Low Transparency & Explainability）：複雜決策過程往往難以追蹤與解釋，形成「黑箱」問題。  
- 🛡️ **安全與可控性風險**（Security & Control Risks）：若行為失控或被惡意利用，可能對環境或社會造成不可預測的風險。  
- 💸 **資源消耗與學習成本高**（Resource Intensive & High Learning Cost）：維持感知、推理與規劃能力需要大量算力與資料，持續學習也可能導致試錯成本過高。  
- 🧱 **環境依賴**（Environment Dependence）：若感知或模擬環境不足，智能體效能會大幅下降。  

✨ **總結**：`智能體導向 AI` 擅長在 **自主決策與複雜任務規劃** 場景中，透過其 **自主性、目標導向、環境感知與持續學習能力** 來解決問題。然而，其 **不可預測性、責任歸屬不清、資源需求與對齊風險** 也使其在實踐中面臨挑戰。因此，在落地 `智能體導向 AI` 項目時，需特別考量 **治理導向** 與 **協作導向** 的輔助，以確保自主行為仍在可控、可解釋與可問責的框架下運作：

- ☸⚖️ **治理導向**：治理提供**制度性保護**與**合規檢核**，智能體導向則提供**自主效率**；兩者需協同設計，以確保自主行為在制度框架下可被**監督與問責**。  
- ☸🤝 **協作導向**：協作導向強調**人本互動**與**透明性**，智能體導向則強調**自主決策**與**策略性**；兩者需透過 **解釋性介面、回退機制與人介入節點** 來平衡自主性與人本需求，確保自動化決策仍在可理解與可信任的框架下運作。  

## 🧭 理論創新點：<br/>🎯智能體「自主閉環」

在智能體研究中，「自主閉環」逐漸被視為**智能的核心機制**而非單純的技術手段。它如同生物體的感知—行動迴路，透過持續的 「**感知（Perception）—決策（Decision-making）—行動（Action）—學習（Learning）** 」循環，使智能體能在真實或模擬環境中保持適應性與目標導向 [@russell2021]。  

- 📘 **理性智能體模型**（Rational Agent Model）：Russell & Norvig 系統化提出「理性智能體」的定義，強調智能體應根據感知與目標選擇最優行動 [@russell2021]。  
- 🤖 **情境主義 AI**（Situated AI）：Brooks（1991）指出智能體必須透過直接的感知—行動迴路與環境互動，才能展現真正的智能 [@brooks1991]。  
- 🏭 **應用實踐印證**：在自動駕駛、智慧製造、金融交易與無人機群中，智能體的自主閉環設計確保了即時性、適應性與長期目標追蹤。  

智能體也可以分為不同的類型，主要看迴圈中「決策」推理過程的複雜度：

- ⚡ **反應式智能體**（Reflex Agents）：
    - **特點**：「迴圈」簡化，僅依賴「條件–動作規則」（if–then rules）來回應環境輸入。沒有內部世界模型，也無需複雜的推理和規劃。它們直接將感知到的環境狀態映射到預設的行動上，就像一種「數位反射」（digital reflex）。
    - **應用**：適合簡單、即時回應的任務，如交通號誌控制、簡單的機器人行為。
- 🧩 **模型式反應智能體**（Model-based Reflex Agents）：
    - **特點**：在反應式基礎上加入「內部狀態」，能追蹤部分環境資訊，處理部分可觀測環境（partially observable environments）。
    - **應用**：智慧型恆溫器、具備記憶功能的清掃機器人。
- 🎯 **目標導向智能體**（Goal-based Agents）：
    - **特點**：不僅回應環境，還會考慮「是否能達成目標」，具備規劃能力，能在多種可能行動中選擇最能達成目標的方案。
    - **應用**：自駕車路徑規劃、導航系統。
- ⚖️ **效用導向智能體**（Utility-based Agents）：
    - **特點**：除了達成目標，還會衡量「達成的好壞程度」，引入效用函數（utility function），在多個可行方案中選擇最優解。
    - **應用**：推薦系統、投資決策輔助系統。
- 📚 **學習型智能體**（Learning Agents）：
    - **特點**：能根據經驗修正行為策略，持續提升效能，包含「學習模組」來改善決策。
    - **應用**：強化學習代理（如 AlphaGo）、自適應廣告投放系統。
- 🏗️ **階層式智能體**（Hierarchical Agents）：
    - **特點**：將任務分解為子任務，透過層級化結構進行規劃與執行。
    - **應用**：機器人任務規劃（如「去廚房 → 開門 → 取物」）。
- 🤝 **多智能體系統**（Multi-agent Systems）：
    - **特點**：由多個智能體組成，彼此協作或競爭，共同完成任務。
    - **應用**：自駕車群體協調、分散式供應鏈管理、多人遊戲 AI。

✨ 這樣一來，從最簡單的 **反應式** 到最複雜的 **多智能體系統**，清楚展現了「決策推理複雜度」演進出**閉環即智能的生成力**，避免靜態規則的僵化，讓 AI 在複雜情境下有自主行動力，但相對風控需求也升高。

***

## 🔬 深入智能體導向

以下就 `智能體導向 AI` 的 **知識姿態**、**意圖**、**預設行動**，聚焦於「自主性與目標導向」模型，探討如何建立並運營「可持續且具適應性」的自主系統，涵蓋 **智能體架構**、**AI 編排** 與 **AI 對齊** 三大面向，逐層展開自主化、策略化與可控化的智能體內容。

### 🤖⛑ 智能體架構

根據智能體與多代理人系統的研究實踐（如 [@brooks1991]、[@russell2021]、[@sutton2018rl]），`智能體導向 AI` 架構常以 **自主決策** 與 **環境感知** 為基礎，可以總結出以下具體層次及相關元素：

- 👁️ **感知層**：感測器、數據輸入，確保智能體能持續蒐集環境訊號。  
- 🎯 **決策層**：規劃與推理模組，將感知轉化為行動策略。  
- 🦾 **行動層**：執行器或軟體代理，將決策轉化為具體行動。  
- 🔄 **學習層**：強化學習與回饋機制，持續優化行為策略。  

**研究實踐顯示**：有效的智能體需將技術能力映射到任務流程，涵蓋感知蒐集、策略規劃、行動執行到學習迭代。  

- 📚 **關鍵元件**：感測器、決策模組、行動執行器、學習演算法、模擬與真實環境。  
- 🎯 **成功指標**：任務完成率、決策效率、適應性、長期目標達成度。  
- ⚙️ **制度化流程**：感知—決策—行動—學習需對應到可追溯、可調整、可持續的閉環設計。  
- 🛡️ **風險緩解機制**：設置「安全閘門」與「人介入節點」，確保偏差行為能被即時偵測與修正。  
- 🔄 **持續迭代**：智能體架構需隨環境與任務動態調整，避免設計落後於實際需求。  

可以說 `智能體導向 AI` 的 **知識姿態** 與「[情境主義](02----schools_paradigms.zh-hant.md)」高度相關：**以感知—行動閉環將智能紮根於環境互動**。這確保了相關的 **意圖**（如提升自主性、追求長期目標）與 **預設行動**（如即時決策、持續學習）能在系統中被有效執行與監測，並直接影響 **任務成功或失敗**。

`智能體導向 AI` 的架構，和以下其它導向對比：

- ☸⚖️ **治理導向 AI**：偏重合規、審計與制度性保護，確保 AI 符合法律與倫理規範，但在自主性與效率上較弱。  
- ☸🤝 **協作導向 AI**：偏重人本互動與採納體驗，智能體導向則偏重自主決策與長期目標；若缺乏協作層與信任層，容易與人類需求脫節。  

### 🤖🏢產業應用

`智能體導向 AI` 的應用實踐，通常落在 **自動駕駛、智慧製造、金融交易、無人機群與智慧城市**。

- 🚗 **自動駕駛**：車輛作為智能體，需在複雜交通環境中即時感知、決策與協調。  
- 🏭 **智慧製造**：工廠中的機器人與生產線代理協同運作，實現柔性製造與即時調度。  
- 💹 **金融交易**：高頻交易代理需在毫秒級市場波動中自主決策，並避免系統性風險。  
- 🛩️ **無人機群**：多架無人機需協同完成監測、運輸或救援任務，涉及分工與避碰。  
- 🌆 **智慧城市**：交通、能源與公共服務代理需在城市基礎設施中協調，提升效率與韌性。

這些場景需共同考量並解決與 **自主性與可控性** 相關的挑戰，特別是：  

- **AI 編排**：如何在多代理人、多環境下協調智能體行為，避免衝突或資源浪費。  
- **AI 對齊與控制**：如何確保智能體的行動與人類價值、組織目標一致，並在偏差時能即時干預。  
- **任務挑戰**：如何在不確定性、資源限制與多重目標衝突下，仍維持高效能與高可靠性。  

可以說，這正是 **自主系統與人類生活交織的主要應用領域**：智能體導向 AI 不僅是技術問題，更是 **設計、治理與產業競爭** 的交匯點。

### 🤖🎼 AI 編排

在 `智能體導向 AI` 中，**AI 編排（Agent Orchestration）** 指的是如何在多智能體系統中，根據一組共享或分層的目標，協調不同代理的角色、任務與互動。這不僅是技術流程的調度，更是 **策略性分工、資源分配與衝突解決** 的機制。  

- 🎯 **目標分解與分配**
  - 🧩 將全域目標拆解為子任務，分配給不同智能體（如規劃代理、執行代理、監督代理）。  
  - 📊 使用任務分配演算法（如拍賣式分配、任務匹配）確保資源利用最佳化。  

- 🤝 **協作與協商**
  - 💬 智能體之間透過通訊協定（如 FIPA-ACL、MCP）交換意圖與狀態。  
  - ⚖️ 採用協商機制（negotiation protocols）、投票或博弈理論方法來解決衝突。  

- 🔗 **角色與層級編排**
  - 🏛️ 採用分層式架構：高層代理負責策略規劃，低層代理負責執行。  
  - 👥 設計「專家代理」與「協調代理」角色，形成分工明確的多代理團隊。  

- 🛡️ **安全與風險控制**
  - 🚨 設置監督代理（monitor agents）持續檢查行為是否偏離全域目標。  
  - ⏹️ 保留「緊急中止」與「回退」機制，避免單一代理的錯誤擴散至整個系統。  

- 🔄 **學習與適應**
  - 📚 多代理強化學習（MARL）讓代理能在互動中共同學習策略。  
  - 🌍 系統層級的回饋管線，確保全域績效（如效率、公平性、穩定性）持續優化。  

👉 `智能體導向 AI` 的編排，核心在於 **如何讓多個自主代理在共享或部分衝突的目標下，形成可協作、可監督、可持續的行動網絡**。這使得 AI 不僅能單獨行動，更能在群體中展現「分工—協作—協商—整合」的能力，成為複雜系統中的有效行動者。

### 🤖🤝 AI 對齊

在 `智能體導向 AI` 中，**AI 對齊** 的核心是將自主行為與人類價值、倫理與社會目標對齊 [@gabriel2020alignment]。  這需要把對齊機制嵌入「感知（Perception）—決策（Decision-making）—行動（Action）—學習（Learning）」閉環的每一環節：

- 👁️ **感知（Perception）：約束輸入與語義對齊**
  - 📊 資料治理與語義映射：以資料標準、特徵審核與語義對齊（ontology）降低觀測偏差。  
  - 🎯 不確定性估計：採用校準機制（calibration）、貝葉斯或集成不確定性評估，讓決策能感知風險區間。  
  - 📝 人類標註與偏好蒐集：透過對比式標註與偏好資料蒐集，為逆強化學習與獎勵建模提供高信噪比信號。  
- 🎯 **決策（Decision-making）：把價值轉化為規則**
  - 🔄 逆強化與偏好學習：用 IRL 或偏好學習推估人類價值函數，使策略優化朝向可解釋目標 [@ng2000irl]。  
  - 🤝 合作式 IRL（CIRL）：把人類—AI 互動建模為博弈，允許智能體在不確定人類目標時主動查詢與協調 [@hadfieldmenell2016cirl]。  
  - 💻 決策即程式（Decision-as-code）：將安全邊界、資源上限、影響正則化等約束編碼化，於策略部署前後自動檢查。  
- 🦾 **行動（Action）：可中斷、可回退、低副作用**
  - ⏹️ 安全可中斷（Safe Interruptibility）：設計「隨時可切斷」且不懲罰被中斷的控制邏輯 [@orseau2016interruptibility]。  
  - 🧪 回退機制與沙盒執行：在高風險任務採用影子模式或雙軌決策，行動先於沙盒驗證再上線。  
  - 🌱 影響最小化：透過副作用懲罰與變更範圍約束，降低不可逆或過度擾動的行動策略。  
- 🔄 **學習（Learning）：持續校準與獎勵建模**
  - 🏆 獎勵建模（Reward Modeling）：以人類評審迭代學習獎勵函數，替代難以手工設計的目標 [@leike2018rewardmodeling]。  
  - 📚 離線／線上強化學習切換：先在離線數據上做保守估計，再以線上小步探索加人類監督持續調整 [@sutton2018rl]。  
  - 🚨 目標漂移監測：持續檢測策略與獎勵分布漂移，當出現「高分但低價值」跡象時觸發重訓或人工審核。  
- 🛡️ **橫向機制：問責與審核**
  - 👤 人類在迴路／監督中：在關鍵節點插入審核與覆核（approval gates），保留人類最終裁決權。  
  - 🔍 可解釋性與反事實檢驗：提供原因路徑與反事實分析，支援「若不採此行動，後果如何」的審議。  
  - 📈 指標體系：同時追蹤任務績效、對齊品質（偏好一致度、可中斷合規率）、安全事件率與回復時間。  

👉 **總結**：只有把「感知—決策—行動—學習」每一環節都嵌入具體對齊機制，並以可中斷、可回退、可審核的制度化設計貫穿閉環，才能把「對齊」從口號變成工程與治理上的可驗證事實。

### 🤖☯️利害關係人

以下**AI 導向**，通常涉及利害關係人，有不同的焦點及目標。

- ☸🤖 **智能體導向 AI**：強調「自主性」，人類行為者更多是被代理、監督或互動對象，參與度雖相對有限，但關鍵時的反饋及介入機制十分重要。
- ☸🤝 **協作導向 AI**：強調「自願參與」，人類行為者能基於意願與責任選擇是否主動參與，這是建立信任與透明的基礎。  
- ☸⚖️ **治理導向 AI**：強調「制度約束」，透過法律、政策與合規機制確保 AI 行為在可控範圍內，但人類參與多為被動遵循。  

 ☯️**互補性**🤝：在實務中，三者宜按功能需求，依序檢查並系統性結合——治理導向提供「**底線安全**」，協作導向提供「**人本採納**」，智能體導向提供「**自主效率**」。  

::: {.callout-note #nte-multistakeholder-compare title="🧩 三導向對照利害關係人 🌍" collapse=false open=true}

|                                       | 協作導向 AI                                                              | 治理導向 AI                                                  | 智能體導向 AI                               |
| ----- | ---------- | ---------- | ---------- |
| _**導向焦點**_                            | **自願參與**<br>（Voluntary Participation）                                | **制度約束問責**<br>（Institutional Accountability）<br>         | **智能體自主性**<br>（Autonomous Agency）      |
| _核心價值_                                | 信任、透明、共創、使用者賦能                                                       | 合規、風險控制、問責                                               | 自主性、效率、適應性                             |
| _主要風險_                                | 效率摩擦、資源需求、責任模糊                                                       | 成本高、創新受限、速度降低                                            | 不可預測性、責任歸屬不清、倫理風險                      |
| _**利害關係人**_                           | 通常以👥 **使用者與公民**為主                                                   | 通常以🏛 **監管者** 規範平台為主                                     | 通常以技術實現**某特定**利害相關人角色為主                |
| 🏛 **監管者** <br/>（政府內部、外部監管機構）         | - 透過 **參與式審議** 與 **公開諮詢** 讓政策制定更透明。<br/>- 公民與專家可自願參與政策討論，影響 AI 部署規範。 | - 制定 **強制性法規**（如 GDPR、AI Act）。<br/>- 要求企業必須遵守隱私、風險與合規檢核。 | - 設定 **自治邊界** 與 **行為規範**，確保智能體不脫離政策框架。 |
| 🧑‍💼 **管理者** <br/>（組織內部決策者）          | - 鼓勵跨部門合作，確立組織的用戶參與架構及協作需求<br/>- 透過 **共創工作坊** 與 **透明化回饋** 確保用戶參與架構。  | - 建立 **合規管線** 與 **稽核制度**。<br/>- 確保所有 AI 部署符合監管要求。        | - 聚焦 **任務分派與資源配置**，讓智能體能自主完成策略性任務。     |
| 🎨 **設計師與開發者**<br/>（組織內部人員）      | - 基於 **使用者研究** 與 **跨域協作**制定參與架構。<br/>- 強調 **人本互動設計** 與 **解釋性介面**。    | - 必須遵循 **設計標準** 與 **合規檢查清單**。<br/>- 開發過程需保留 **審計日誌**。    | - 專注於 **強化智能體自主性**，設計學習與決策模組。          |
| 👥 **使用者與公民**<br/>（政府與組織外） | - **自願參與** 系統互動、回饋與共創。<br/>- 公民可選擇是否參與數據共享、政策討論或平台治理。                | - 受制於 **隱私政策** 與 **使用條款**。<br/>- 公民的參與多為被動遵循制度，而非主動共創。   | - 作為 **智能體互動對象**，多以被動接受或監督角色出現。        |
: 🧩 三導向對照利害關係人 🌍 {#tbl-multistakeholder-compare}

:::

## 🔄歷史演進🗿

`智能體導向 AI` 的發展以「決策複雜度與自主性」為主線，可發現聚焦從「感知—回應」到「感知—決策—行動—學習」的閉環演進，以及與 [具身派 AI](08----embodied_ai.zh-hant.md) 的共同交織演進。

- 🎙️ **1960年代 — 模式匹配對話的起點**
    - 💬 **Eliza**：展示了「感知—回應」的雛形（基於模式匹配），能模擬對話但不具備 **世界模型（World Model）** 與規劃能力，尚未形成完整的代理迴圈。
- 📜 **1970年代 — 認知與分散計算的奠基**
	- 🧠 **符號推理與規則系統**（Symbolic Reasoning & Rule-based Systems）：認知科學與早期 AI 強調以符號邏輯與規則來模擬人類思維，為後續「理性智能體」模型奠基。    
	- 🔗 **分散計算與 Actor Model**（Distributed Computing & Actor Model）：提出以「訊息傳遞」與「分散行為」為核心的計算模式，為後來的 **多代理系統（MAS）** 提供理論基礎。
- 📟 **1980年代 — 代理架構論戰與行為式革命**
	- 🧠 **符號式 AI 陣營**（Symbolic AI Camp）：主張智能體需要一個內部的 **世界模型**（World Model），透過推理與規劃來決定行動。代表性成果為 **認知架構**（Cognitive Architectures）：
	    - 🧩 **SOAR**（State, Operator, And Result）：以「問題空間搜尋」為核心，透過比較當前狀態（State）、應用操作（Operator）來達到目標狀態（Goal），並預測不同操作的結果以選擇最佳路徑。
	    - 🧩 **ACT-R**（Adaptive Control of Thought—Rational）：主張知識由 **宣告式知識**（Declarative Knowledge）與 **程序式知識**（Procedural Knowledge） 組成，結合符號與聯結主義的混合知識庫，模擬人類的認知過程。        
	- 🤖 **行為式架構／情境主義**（Behavior-based / Situated AI）：Rodney Brooks  中挑戰符號主義，提出 **行為式架構**（Subsumption Architecture），強調智能體應透過「感知—回應」迴路與環境直接互動，避免厚重表徵與複雜推理 [@brooks1991]。
- 🧩 **1980–1990年代 — 分散式與具身思潮共振**
	- 🔗 **分散式 AI**（Distributed AI）：推動以多行為／多單元協作的設計哲學，為後來的多代理系統（MAS）提供理論基礎。    
	- 🦾 **具身派 AI**（Embodied AI）：與代理研究相互強化，主張「行動先於表徵」，閉環互動被視為智能的必要條件，為後續的機器人學與強化學習實驗提供場景支持。
- 🎮 **1990年代 — 規範化與範式確立**
    - 🧱 **代理人導向程式設計**（Agent-oriented Programming, AOP）：以代理為核心的軟體範式逐步成形，將消息傳遞與行為解釋作為抽象單元，為後續多代理系統與平台鋪路。
    - 🏛️ **FIPA 標準與平台萌芽**（FIPA Standards & Platforms）：國際社群推動軟體代理標準化，催生後續 JADE、JACK 等平台，促進互操作與通訊規範在產業與研究場景落地。
    - 🌐 **網路與資訊代理**（Web/Information Agents）：隨網際網路普及，早期資訊檢索與過濾型代理擴展應用範圍，為互動式代理與多代理協作奠定基礎。
- 📡 **2000年代 — 多代理系統成熟與產業落地**
    - 🧩 **多代理系統（Multi-agent Systems, MAS）落地**：在網路協議、供應鏈、分散式模擬與博弈場景中，代理展現協作、分工與資源分配能力，FIPA/JADE 等平台被廣泛採用。
    - 🤖 **機器人與群體智能（Robotics & Swarm）**：多感知／動作模組與任務分配機制普及，群體式協同控制思路加深代理導向在具身場景的實踐連結。
- **💼 2010年代 — 深度學習驅動、多代理系統與具身學習的拓展**
    - - 🌐 **多代理系統（Multi-agent Systems, MAS）**：在網路協議、供應鏈管理、模擬與博弈環境中廣泛應用，展現分散式決策與協作能力。    
	- 🎯 **理性智能體模型系統化**（Rational Agent Model Systematization）：Russell & Norvig 在《Artificial Intelligence: A Modern Approach》第三版（2010）中，將「感知—決策—行動—學習」閉環定義為智能體的核心框架 [@russell2021]。    
	- 🦾 **具身學習（Embodied Learning）**：機器人透過強化學習在物理環境中學習導航與操作，與 MAS 的「分散決策」形成互補，推動 embodied AI 與 agent-oriented AI 的共演。	 
	- 🧪 **深度強化學習突破**（Deep Reinforcement Learning）：2015–2016 年 DeepMind 的 DQN 與 AlphaGo 展示了深度學習與 RL 的結合，標誌代理能在複雜環境中自主學習策略，推動「感知—決策—行動—學習」的整合。
    - 🕹️ **3D 模擬與基準化平台**：高保真環境（如  Habitat、MineRL 等3D 模擬）促進任務可重現、測試與對比，代理訓練評估系統化，「感知—決策—行動—學習」閉環能力被實證強化。
- 🛠️ **2020年代 — 行動導向與知識系統融合**
    - 📊 **知識系統與自然語言整合**：代理結合知識圖譜、語言介面與工具調用，能執行跨域長鏈任務與目標分解，從「單步執行」走向「多步編排」。
    - 🧑‍🤝‍🧑 **代理工作流普及**（Agentic Workflows）：人機協作、任務分解與審核機制成為常態，平台化工具鏈（如 LangChain、AutoGPT）支持代理在企業流程與知識工作中落地。
    - 🕹️ **模擬與測試平台**（Simulation & Benchmark Platforms）：Habitat、MineRL 等 3D 環境持續用於驗證「感知—決策—行動—學習」閉環，並與 LLM 代理結合，推動 embodied + agentic AI 的融合。
- 🤝 **2024年 — LLM 驅動的多代理協作**    
	- - 🤖 **LLM 驅動的工具調用**（LLM-driven Tool Use）：大型語言模型透過函數調用與 API 編排，成為代理的「決策中樞」，支援跨模態與跨平台的任務協作。
    - 🦾 **具身大型語言模型基礎模型**（Embodied LLM Foundation Models）：將感知、語言與控制整合，跨模態學習與行動規劃加速融合。        
    - 🤖 **基於大型語言模型的智能體**（LLM-based Agents）：大型語言模型被封裝為具備規劃、工具調用與角色分工的代理，支援跨職能協作（產品、設計、工程、測試）與結構化任務分解。        
    - 🧑‍🤝‍🧑 **LLM 驅動的多代理系統**（LLM-driven Multi-agent Systems, MAS）：透過角色分工與協作，解決如軟體開發流程（例：MetaGPT）、模擬虛擬軟體公司（例：ChatDev）等複雜場景。        
    - 🎯 **自主性提升**（Autonomy Enhancement）：代理不僅能完成單一任務，還能在團隊中進行批評、協調與任務分配，展現更高層次的自主閉環。        
- 🛰️ **2025年以後 — 平台化、標準化與生態化**    
    - 🔗 **標準化與跨平台協議**：API/MCP 協議推動不同代理框架與具身系統的互操作，形成跨平台的協作生態。        
    - ⚖️ **多代理決策與治理框架**（Multi-agent Decision-making & Governance Frameworks）：建立審計、監控與合規機制，確保代理在自主決策過程中仍符合人類價值與法規要求。        
    - 🤝 **人機協作深化**（Human–AI Collaboration Deepening）：人類與 AI 在混合團隊中協同決策，AI 提供即時建議與工具調用，人類保有最終決策權。        
    - 🏯 **地緣政治摩擦**（Geopolitical Frictions）：中美在自主系統與具身智能標準制定上的競爭，影響全球產業與治理。
    - 🧭 **生態化創新**（Ecosystem Innovations）：代理不再是單一應用，而是嵌入於平台與產業鏈，形成可持續擴展的智能生態系統創新。

👉 總結來說，`智能體導向 AI` 與 `具身派 AI` 在歷史上呈現「理論—實踐」的互補：前者提供 **自主決策與目標導向框架**，後者提供 **感知—行動的具體場景**。兩者的共演推動了從 **情境主義** 到 **多代理人具身智能** 的演進，並在生成式 AI 時代融合為新一代的 **自主協作生態**。

## 🤖小結🦴

`智能體導向 AI` 的核心價值在於 **自主性、目標導向與環境感知**。在自動駕駛、智慧製造、金融交易、無人機群與智慧城市等場景中，它提供一種以 **感知—決策—行動—學習** 閉環為基礎的運作模式，讓 AI 能在動態環境中持續適應、規劃並執行行動。  

智能體導向提升了系統的 **效率、適應性與長期目標追蹤能力**，但也帶來 **不可預測性、責任歸屬與資源消耗** 的挑戰。  

- **🎯 自主性**：能在無人監督下持續感知環境並執行決策。  
- **🧭 目標導向**：具備長期與短期目標規劃與調整能力。  
- **👁️ 環境感知**：持續蒐集並解讀環境訊號，形成決策依據。  
- **🔄 持續學習**：透過強化學習與回饋機制不斷優化行為策略。  
- **🤝 協作互動**：能與其他智能體或人類協作，形成多代理人系統。  

`智能體導向 AI` 的應用核心價值，和以下其它導向對比：  

- ☸⚖️ **治理導向**：治理偏重制度性保護與合規檢核，智能體則偏重自主決策與效率；兩者需協同設計，以確保自主行為在制度框架下可被監督與問責。  
- ☸🤝 **協作導向**：協作偏重人本互動與採納體驗，智能體則偏重自主性與策略性；兩者需透過解釋性介面、意圖可視化與回退機制，平衡自主性與人本需求。  

綜上所述，`智能體導向 AI` 的核心價值在於將 **自主性、目標導向與持續學習** 嵌入技術生命週期，確保 AI 能在高度不確定與多目標衝突的環境中仍具備 **可控性、透明性與責任可追溯**；在跨域應用與多代理人場景中，它是推動長期可持續運行與產業競爭力的關鍵基礎，同時要求組織在 **安全、資源與治理** 上做出審慎的設計與投資。


## 🤖AI 應用啟發💡

`智能體導向 AI` 的核心價值，在於 將**自主性、目標導向與環境感知**模型**系統化**，並把這些閉環原則嵌入 AI 的全生命週期中。它不僅確保技術能在複雜環境中獨立運作，也能透過持續學習與閉環調整，推動效率、適應性與長期目標的實現。

以下列出幾個關鍵思考面向，幫助您將其價值融入具體的 AI 解決方案：

- 🎯 **問題意識**（Problematics）：必須在高自主性或高風險場景優先考慮智能體導向，如自動駕駛、無人機群、智慧製造與金融交易。  
- 🗺️ **建構資源**：建立感測器網絡、決策模組、行動執行器、模擬與真實測試環境，支援「感知—決策—行動—學習」閉環。  在多代理架構中，則需明確定義各個智能體的角色與溝通方式。
- ⚡ **智能加值**：採用強化學習、逆強化學習、偏好學習與不確定性估計，提升策略規劃與行動的可靠性。  
- 🏭 **佈署條件**：適合在動態、高變化、需即時決策且多源資訊融合的環境中部署。在上線前完成安全測試、風險評估、責任分擔設計與人類監督節點；採分階段部署與持續監控。 
- 🔄 **常見補強方法**：定期進行策略審查、異常行為檢測、對齊品質評估與外部安全審核。利用 **人類回饋強化學習**（RLHF）來優化其行為策略。
- 🤝 **人機協同**：在任務設計中引入人類監督者、風險治理專家與工程團隊，將自主需求轉譯為可執行的安全標準。  
- 🛡️ **可中斷性**：確保人類能在必要時即時介入或中斷，避免智能體行為失控。  
 
總之，智能體 AI 的設計與部署不僅要仰賴模型與演算法，更需要對其與真實世界的互動進行全面管理，發揮其如**自主性**、**動態適應性**和**協作能力**等特性。從智慧助理到複雜的跨領域協作，智能體 AI 的設計與部署是在開放環境中實現**自主決策**與**高效協作**的關鍵。

`智能體導向 AI` 的應用核心價值，和以下其它導向對比：

- ☸⚖️ **治理導向**：治理提供制度性保護與合規檢核，智能體導向則提供自主效率；兩者需協同設計，以確保自主行為在制度框架下可被監督與問責。  
- ☸🤝 **協作導向**：協作導向強調人本互動與透明性，智能體導向則強調自主決策與策略性；兩者需透過 **解釋性介面、回退機制與人介入節點** 來平衡自主性與人本需求。  

特別需要強調的是：**自主性** 是智能體導向 AI 的根本特徵。與協作導向不同，這裡的核心不是「自願參與」，而是 **持續感知、獨立決策與長期目標追蹤**。這種自主性使智能體導向 AI 能夠在高度不確定的環境中展現 **效率、適應性與韌性**，但同時也要求嚴格的 **對齊與風險治理**。

在實務應用上不同領域，`智能體導向 AI` 帶來以下可能啟發：

- 🚗 **自動駕駛**：設計能即時感知環境、規劃路徑並持續學習的車輛，確保安全與效率。  
- 🛰️ **無人機群**：在災害救援或物流配送中，透過多代理人協作與自主決策提升任務完成率。  
- 🏭 **智慧製造**：在工廠自動化中，導入能自主調整流程的智能體，提升生產彈性與資源利用率。  
- 💹 **金融交易**：在高頻交易與風險管理中，應用能即時感知市場變化並自主調整策略的智能體。  
- 🌐 **智慧城市**：在交通、能源與公共安全中，部署能持續學習與優化的自主代理，提升城市運行效率。  

👉 **總結啟發**：智能體導向 AI 的價值不僅在於「完成任務」，而在於 **如何自主感知、如何持續學習、如何在不確定環境中保持可控性**。自主性是其與協作導向的根本區別，確保智能體導向 AI 不僅是技術框架，更是 **效率、適應性與風險治理** 的實踐。

## ☸接下來🪸

瞭解基於 **自主性** 與 **模型系統** 框架、強調「**自主效率**」效能，追求 長期策略「**動態適應**」的 `智能體導向 AI` 後，讀者可以繼續：

- ⇆🚥對比：
	* **5.1** ☸🎯 **[任務導向型](05-01-oriented_task.zh-hant.md)**
	* **5.2** ☸🛠 **[工具導向](05-02-oriented_tool.zh-hant.md)**
	* **5.4** ☸🤝 **[協作導向／以人為本導向](05-04-oriented_collaborative.zh-hant.md)**
	* **5.5** ☸⚖️ **[治理導向](05-05-oriented_governance.zh-hant.md)**
<!--		* **5.3** ☸🤖 **[智能體／代理人導向](05-03-oriented_agent.zh-hant.md)**-->
* ⮤🚦探究 [第壹篇 ㉄](01----problematics.zh-hant.md)　AI 問題意識
	* **1.3** 🔤⚓ [符碼紮根問題](01-03-Symbol_Grounding_Problem.zh-hant.md)
	* **1.4** 🖼️⏱️ [框架問題](01-04-Frame_Problem.zh-hant.md)
	* **1.6** 🎯🛡️ [對齊與控制問題](01-06-Alignment_Control_Problem.zh-hant.md)
	* **1.7** 🗫🎲 [語言賽局](01-07-Language_Games.zh-hant.md)
* ⮦🚦探究[第捌篇 🦾](08----embodied_ai.zh-hant.md)　「具身派」AI：
	* **8.3** 🦾🔄🖼️ [自適應機器人](08-03-adaptive_robotics.zh-hant.md)
	* **8.4** 🦾🤝💪 [人機互動](08-04-human_robot_interaction.zh-hant.md)
	* **8.5** 🦾🛡️🚨 [機器人安全與穩健性](08-05-robot_safety_and_robustness.zh-hant.md)
	* **8.6** 🦾🧭🎯 [任務與目標規劃](08-06-robot_tasks_and_goals.zh-hant.md)
* ⮦✨應用啟發 [第拾篇 🌉](10----ai_engineering.zh-hant.md)　AI工程：
	* **10.2** 🌉🤖🚨 [智能體可靠性與評估](10-02-agent_reliability_evaluation.zh-hant.md)
	* **10.4** 🌉🔗📒 [知識驅動生成（RAG）](10-04-retrieval_augmented_generation.zh-hant.md)
	* **10.5** 🌉🪟🧭 [脈絡工程](10-05-context_engineering.zh-hant.md)
	* **10.6** 🎁🌱🚀 [AI 產品經理](10-06-AI_PM.zh-hant.md)
