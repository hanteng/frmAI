---
title: "🏛️🤖💬 自動對話系統"
---
`自動對話系統`（Automatic Dialogue Systems）透過預先定義的**符號**與**規則**來模擬人類對話。其運作原理是將人類語言解構為可處理的符號體系，再利用**模式匹配**與**規則腳本**進行回應。其中，由 Joseph Weizenbaum 開發的 **ELIZA** 便是一個具代表性的應用範例，它透過簡單的模式匹配，成功模擬了心理諮詢師的回應。

作為**符號流 AI**的早期代表，此類系統與**專家系統**類似，其核心思想是將人類專家的知識符號化、規則化，並以**形式邏輯**的方式進行推論與回應。由於自動對話系統通常依賴手動編寫的**知識庫**與**推理引擎**，因此在封閉、有明確定義的場景下表現較為出色。

***

作為人機互動的智能對話實現，**自動對話系統**與當代的**大語言模型（LLM）聊天機器人**有著根本上的運作區別：

- 🏛️🤖💬 屬於**符號流 AI**的自動對話系統，基於明確的邏輯規則運作，其**推理鏈**可追蹤且**可解釋**，但因其能力有限遭遇到如日本早期對其「人工無能」的評價。
    
- 🌀🧞‍♀️🗪 屬於**統計流 AI**的 LLM 聊天機器人，則是在海量數據上進行**機率性關聯**學習，將語言符號轉換為**向量空間**中的數值向量。其回應基於機率預測，因此生成過程**可解釋性較低**。

## 🔬 細說

自動對話系統的核心運作流程包含三個階段：

- 🟢 **解析（Parsing）**：系統會將使用者的輸入進行分解與標識，找出關鍵字或句法結構等符號。
- 🟠 **處理（Processing）**：系統根據解析出的符號，在預設的規則庫中尋找匹配項，並觸發相應的動作。
- 🔴 **產生（Generating）**：系統結合處理結果與預設的回應模板，生成最終的對話輸出。

這套流程保證系統穩定性與可控性，但同時也限制其靈活性與適應性。

### ✨ 特性

由於其運作基於離散的符號與明確的邏輯規則，自動對話系統不擅長掌握**對話脈絡**（dialogue context），但同時也具備高可解釋性與可控性。

#### 👍 正面特性

對話範圍需被嚴格限定在預設的框架時，符號流的自動對話系統特別適用。

- 🛠️ **高可解釋性**：所有回應均來自預設規則，決策過程透明，便於追蹤與除錯。
    
- 📝 **高可控性**：開發者能精確控制對話流程與內容，避免產生不適當或不準確的回應。
    
- 🔒 **領域知識專精**：適用於醫療、法務等需高度專業知識的封閉領域，能提供可靠且精準的資訊。
    
- 🚄 **高效能**：不需龐大的運算資源，能在低功耗設備上快速運行。
    
- 📈 **穩定性**：回應具備可預測性與一致性，不受訓練數據的影響而改變。

#### 👎 負面特性

儘管具備優勢，其基於規則的本質也存在顯著局限性，難以處理開放或複雜的對話情境。

- 🤯 **缺乏對話脈絡理解**：無法理解對話的深層語意與連貫性，回應常顯得機械且缺乏彈性。
    
- 🔄 **無法處理新情境**：只能回應預先定義好的模式，對於未見過的問題或表達方式則無能為力。
    
- 👨‍💻 **開發與維護成本高**：需人工編寫大量規則與知識庫，隨著對話複雜度增加，維護成本呈指數型成長。
    
- 🤖 **缺乏泛化能力**：無法將一個領域學到的知識應用於其他領域，每個新應用都需要從頭建立規則。
    
- 🗣️ **對話缺乏自然流暢性**：容易產生跳躍式或重複性回應，使用者體驗較差。

## 🔄 歷史演進

自動對話系統的發展歷程可視為**符號流 AI** 在**人機互動**領域的縮影，從簡單的模式匹配逐漸發展到更為複雜的結構化知識應用。

- 🟢 **1966 年：ELIZA** － 作為早期**符號流 AI** 應用的代表，證明了透過簡單的模式匹配能模擬對話，但缺乏真實理解。
    
- 🟡 **1972 年：PARRY** － 模仿偏執型精神分裂症患者的對話，其複雜的規則引擎與**本體論空間**概念的雛形，比 ELIZA 更具深度。
    
- 🟠 **1980s：專家系統** － 隨著**專家系統**的興起，自動對話系統開始與其**知識庫**與**推理引擎**結合，用於特定專業領域，例如診斷系統。
    
- 🔴 **1990s-2000s：語音導覽與客服系統** － 語音辨識技術的進步讓自動對話系統開始應用於電話客服與語音導覽，但其背後的邏輯仍以**規則**為主。

## 🏁 小結與展望

自動對話系統的核心困境在於其僵化的**符號**與**規則**，使其無法應對人類語言的複雜性與多樣性。然而，隨著**統計流 AI** 的興起，特別是**大語言模型**的發展，未來的發展將結合大語言模型與可解釋的知識圖譜與腳本，創造出新一代對話系統。

值得注意的案例是具備腳本式對話策略的「[AI 治療師](https://doi.org/10.48550/arXiv.2412.15242)」。雖然 LLM 負責生成流暢、擬人化的回應，但整體對話流程皆由專家編寫的腳本來引導。這確保了 AI 代理能依據預設規則行事，並允許其決策路徑被檢視，以滿足風險管理與問責制的需求，這在心理健康照護等敏感領域至關重要。

另一個例子是應用於電力系統最佳化的智能代理「[RePower](https://pmc.ncbi.nlm.nih.gov/articles/PMC12010440/)」。它不直接解題，而是扮演**公式生成器**的角色，協助使用者將對情境的描述轉換為精確、可供求解的數學公式，並配合**驗證與改進**流程提供迭代反饋來檢查，最終產出可執行的數學模型，以確保解決方案的可行性與可解釋性。


