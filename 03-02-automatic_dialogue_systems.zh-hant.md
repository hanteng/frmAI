---
title: "🏛️🤖💬 自動對話系統"
tags: 
- 自動對話系統
- 人機互動
- ELIZA 
- 符號主義 
- 專家系統 
- 形式邏輯
- 推理引擎
- 知識庫
- 知識表徵工程
---
`自動對話系統`（Automatic Dialogue Systems）透過預先定義的**符號**與**規則**來模擬人類對話。其運作原理是將人類語言解構為可處理的符號體系，再利用**模式匹配**與**規則腳本**進行回應。其中，由 Joseph Weizenbaum 開發的 **ELIZA** 便是一個具代表性的應用範例，它透過簡單的模式匹配，成功模擬了心理諮詢師的回應。

作為**符號流 AI**的早期代表，自動對話系統與**專家系統**類似，核心思想是將人類專家的知識符號化、規則化，並以符號比對進行推論與回應。由於依賴手動編寫的**知識庫**與**推理引擎**（Inference Engine），它在封閉、有明確定義的場景下表現出色，但在開放對話中顯得僵化。

***

## 🔼 智能對話思考 🤔 

早期的`自動對話系統`不如 **符號流AI** 後來的 **[專家系統](03-03-expert_systems.zh-hant)** ，（例如 1966 年的 ELIZA、1972 年的 PARRY）其實**並沒有**真正使用推理引擎。這些早期系統的特徵是：

- 幾乎完全依賴**模式匹配**與預先編寫的對話腳本。
- 缺乏多步的邏輯推導與規則鏈結。    
- 無法動態組合已知事實來產生新的結論

要到1980 年代，當自動對話系統開始與**專家系統**結合，用於醫療診斷、技術支援等專業領域時，部分系統就會在後端整合**真正的推理引擎**：

- **對話模組**作為**前端**與使用者互動。
- **推理引擎**在**後端**根據專家事先手動編寫的**知識庫**進行推論，產生答案或建議。

這種架構常見於基於[專家系統](03-03-expert_systems.zh-hant)（如 MYCIN 的 EMYCIN 框架）開發的領域專用對話系統。

可以說：
* **早期、開放領域**`自動對話系統` → 沒有推理引擎，純模式匹配。
* **後期、專用領域**`自動對話系統`  → 可能整合專家系統的「推理引擎」（Inference Engine），具備真正的規則推論能力。

## ▶️ 對話系統設計 🥸

自動對話系統的核心運作流程包含三個階段：

- 🟢 **解析（Parsing）**：系統會將使用者的輸入進行分解與標識，找出關鍵字或句法結構等符號。
- 🟠 **處理（Processing）**：系統根據解析出的符號，在預設的規則庫中尋找匹配項，並觸發相應的動作。
- 🔴 **產生（Generating）**：系統結合處理結果與預設的回應模板，生成最終的對話輸出。

這套流程保證系統穩定性與可控性，但同時也限制其靈活性與適應性。

### ✨ 特性

由於其運作基於離散的符號與明確的邏輯規則，自動對話系統不擅長掌握**對話脈絡**（dialogue context），但同時也具備高可解釋性與可控性。

#### 👍 正面特性

對話範圍需被嚴格限定在預設的框架時，符號流的自動對話系統特別適用。

- 🛠️ **高可解釋性**：所有回應均來自預設規則，決策過程透明，便於追蹤與除錯。
    
- 📝 **高可控性**：開發者能精確控制對話流程與內容，避免產生不適當或不準確的回應。
    
- 🔒 **領域知識專精**：適用於醫療、法務等需高度專業知識的封閉領域，能提供可靠且精準的資訊。
    
- 🚄 **高效能**：不需龐大的運算資源，能在低功耗設備上快速運行。
    
- 📈 **穩定性**：回應具備可預測性與一致性，不受訓練數據的影響而改變。

#### 👎 負面特性

儘管具備優勢，其基於規則的本質也存在顯著局限性，難以處理開放或複雜的對話情境，如「對話缺乏自然流暢性」等問題導致的「人工無能」的評價。

- 🤯 **缺乏對話脈絡理解**：無法理解對話的深層語意與連貫性，回應常顯得機械且缺乏彈性。
    
- 🔄 **無法處理新情境**：只能回應預先定義好的模式，對於未見過的問題或表達方式則無能為力。
    
- 👨‍💻 **開發與維護成本高**：需人工編寫大量規則與知識庫，隨著對話複雜度增加，維護成本呈指數型成長。
    
- 🤖 **缺乏泛化能力**：無法將一個領域學到的知識應用於其他領域，每個新應用都需要從頭建立規則。
    
- 🗣️ **對話缺乏自然流暢性**：容易產生跳躍式或重複性回應，使用者體驗較差。

### 🆚 對比LLM聊天機器人

作為人機互動的智能對話實現，**自動對話系統**與當代的**[LLM聊天機器人](04-02-llm_chatbots.zh-hant)**有著根本上的運作區別：

- 🏛️🤖💬 屬於**符號流 AI**的自動對話系統，基於明確的邏輯規則運作，其**推理鏈**可追蹤且**可解釋**，但因其能力有限遭遇到如日本早期對其「人工無能」的評價。
    
- 🌀🧞‍♀️🗪 屬於**統計流 AI**的 LLM 聊天機器人，則是在海量數據上進行**機率性關聯**學習，將語言符號轉換為**向量空間**中的數值向量。其回應基於機率預測，因此生成過程**可解釋性較低**。

## 🔄歷史演進🗿

`自動對話系統`的發展歷程，從早期的模式匹配到結合專家系統與語音技術，見證了**符號流 AI**在 **[人機互動](08-04-human_robot_interaction.zh-hant)** 領域的演進：

- 😶◼ **1966 年：ELIZA** － 早期符號流 AI 範例，透過簡單模式匹配模擬對話，但缺乏基於形式邏輯的複雜**演繹推理**（deductive reasoning）。  
- 🙀🛋 **1972 年：PARRY** － 模仿偏執型精神分裂症患者的對話，其複雜的規則引擎與**本體論空間**雛形，比 ELIZA 更具深度。  
- 😷🩺 **1980s：專家系統** － 隨著**專家系統**（如 MYCIN 的 EMYCIN 框架）興起，自動對話系統開始與其**知識庫**與**推理引擎**結合，用於特定專業領域，例如診斷系統。  
- 😽☎ **1990s–2000s：語音導覽與客服系統** － 語音辨識技術進步，推動自動對話系統應用於電話客服與語音導覽，但核心邏輯仍以**規則**為主。  

## 💬 人工無能的弱AI

自動對話系統的知識領域局限，以及「人工無能」的評價，為「[強 vs. 弱人工智慧](02-04-agi.zh-hant)」的辯論，提供核心案例與論據：支持弱人工智慧，並挑戰了強 AI 的主張。

自動對話系統能執行特定的任務，**表現得像是**有智慧，ELIZA 和 PARRY 的成功證明，**模擬智慧**是完全可行的，而且甚至能夠通過有限的**圖靈測試**。這有力地支持了**弱 AI** 的立場：機器只需要一套足夠巧妙的規則來處理符號，就能產生看似智能的行為，而不需要任何內在的理解。

## 🪾 小結與展望 ♻

基於明確的邏輯規則運作，**自動對話系統**雖展示了**符號流 AI**的推理**可解釋**性，但因「對話缺乏自然流暢性」等問題導致的「人工無能」的評價，揭示**符號**無法有效**紮根**時的**理解**與**反應**僵化問題。同時，對話的自然流暢性需求，是在多年後的**統計流 AI**的[LLM聊天機器人](04-02-llm_chatbots.zh-hant) 應對克服的。

自動對話系統的核心困境在於其僵化的**符號**與**規則**，使其無法應對人類語言的複雜性與多樣性。然而，隨著 **統計流 AI** 的興起，特別是 **[大語言模型](02-07-large_language_models.zh-hant)** 與 [LLM聊天機器人](04-02-llm_chatbots.zh-hant) 的發展，未來的發展將結合的大語言模型「流暢性」與 [知識圖譜](03-04-knowledge_representation.zh-hant) 與 [專家系統](03-03-expert_systems.zh-hant) 的「可解釋性」，創造出新一代對話系統。

值得注意的案例是具備腳本式對話策略的「[AI 治療師](https://doi.org/10.48550/arXiv.2412.15242)」。雖然 LLM 負責生成流暢、擬人化的回應，但整體對話流程皆由專家編寫的腳本來引導。這確保了 AI 代理能依據預設規則行事，並允許其決策路徑被檢視，以滿足風險管理與問責制的需求，這在心理健康照護等敏感領域至關重要。自動對話系統的**規則腳本**概念及「可解釋性」因此可用來補充 **統計流 AI** 的不足。

## 👉 接下來 🪸

- ⇆🚥 區分「**自動對話系統**」與「**LLM 聊天機器人**」在**對話聊天實現**上的核心差異。  
  前者基於**演繹**，依賴預設的邏輯規則、腳本與模式匹配，追求絕對的「因果關係」與可驗證性；  
  後者基於**歸納**，透過「**機率性關聯**」從大量語料中學習模式，生成流暢且多樣化的回應。  

- ⮦🚦 探究 [第參章 🏛️](03----symbolic_ai.zh-hant) **符號流 AI**（Symbolic AI）的其它條目，評估自己可否說明 **自動對話系統** 與它們的關係，如下所述：  

    - **🏛️⊨∴ [形式邏輯](03-01-formal_logic.zh-hant)**：自動對話系統的運作邏輯，本質上是一種**簡化的符號比對**。它沒有完整的推理引擎，而是透過**模式匹配**來回應，屬於形式邏輯在簡化應用上的體現。  

    - **🏛️🎁🧠 [專家系統](03-03-expert_systems.zh-hant)**：早期的自動對話系統可視為基於模式匹配、但缺少複雜**演繹推理**（deductive reasoning）的專家系統。它們沒有真正的理解能力，而是依賴預先設定的「如果…則…」腳本來回應，本質上是為特定目的設計的「對話專家」。  

    - **🏛️🛠️🏗️ [知識表徵工程](03-04-knowledge_representation.zh-hant)**：早期自動對話系統的核心任務是**知識表徵**，知識僅限於將對話腳本與關鍵字配對。這種簡易的知識工程雖能運作，但也導致對話僵化。  

    - **🏛️🕸💡 [知識圖譜](03-05-knowledge_graph.zh-hant)** 與 **🏛️🌐🔗 [語意網](03-06-semantic_web.zh-hant)**：這些更複雜的符號流技術，為後來的對話系統提供了更豐富的**知識基礎**，幫助系統理解詞彙間的**關係**，讓對話不再僅限於簡單的腳本配對。  

    - **🏛️🌌🗺️ [本體論](03-07-ontology.zh-hant)**：本體論為自動對話系統提供**抽象概念空間**的結構化藍圖。相較於僅用關鍵字比對，本體論能定義詞彙之間的關係與階層，使系統能進行更複雜的語義推理，克服早期的僵化問題。  

