---
tags:
  - 基礎模型
  - 生成模型
  - RLHF
---
# 😵‍💫🧞‍♀️大語言模型 {#sec-large-language-models}

`大語言模型`（Large Language Models, LLMs）因為 2022 年底代表性案例 [LLM聊天機器人](04-02-llm_chatbots.zh-hant) **ChatGPT**的迅速普及，不僅重燃了人們對人工智慧（AI）的熱情，甚至引發了對通用人工智慧（[AGI](02-04-agi.zh-hant)）的遐想。

為了簡要說明 `大語言模型`的關鍵組成技術，本條目依循介紹以下：

- 🧠 神經－符號合流的現代案例：從**注意力機制**到**轉換器架構**的成功，標誌**深度學習**重大突破。
- 🔮 自我監督學習的現代數字文本模型：透過**預訓練**機制，從**海量未標記資料**學習語言結構、知識與世界觀。
- 🔼 神經元思考：神經元思考：連結主義的深度學習透過 **監督式微調** 與行為主義的**強化學習**結合RLHF，將模型的能力與人類**偏好、價值觀**對齊。

為了闡明`大語言模型`，已有幾類 ❝腦補❞ 心智模型假說，解釋其功能及運作：

- 🎞🤯 **巨型自動完成機**（Giant Autocomplete Machine）：LLM 好比文本預測「極致自動完成」仙，能超越自動完成系統猜中下一個詞。
- 🗺️🧭 **巨型統計地圖**（Giant Statistical Map）：LLM 如同詞彙「路徑生成」神，能在高維語意地圖按最可能路徑前行，完成神回應。
- 🗜️😵‍💫 **網際網路文本有損壓縮**（Lossy Compression of Internet Text）：LLM 如「整個網路的海量文本」模型參數壓縮檔，因捨棄細節有損所以難免「產生幻覺」。
- 🎭🧞‍♀️ **人機腦補語言賽局**（Mutual Mental Fill-in Language Game）：LLM 好比聊天「對話藝術」精，能流暢多輪對話贏得使用者信任（❝腦補❞雙贏賽局），填補對話甚至心靈空缺。

## 🎞巨型自動完成機🤯

🏷️ **解釋**：LLM 本質上是一個極度先進的 `巨型自動完成機`（Giant Autocomplete Machine），為了要**預測**最有可能出現的下一個詞，LLM 基於海量文本資料中習得語言的統計模式，並據此[生成](06-05-analysis_generative.zh-hant.md) 連貫文本，參與流暢對話。這比喻說法由**Grant Sanderson** 等人推廣，突顯使用者感知到的是 LLM [模仿人類溝通](01-01-Turing_Test.zh-hant.md)的「智慧」[@Sanderson2023-gpt-visual-intro;@Manning2022-understanding-reasoning-with-llms]。

- 🎯 **解釋較準部份**：
    - 🤯 **簡單易懂**：用過當代搜索界面有「自動完成」或「自動補完」的使用者，能將LLM簡單理解為更強大的「接話器」。
    - 🎞 **核心機制**：精準捕捉模型根本的 [機率性關聯](04-01-probabilistic_association.zh-hant) 本質，與依序生成詞彙的過程。
    - ⚠️ **凸顯限制**：突顯其「[🌀統計流](04----statistical_ai.zh-hant.md)」機器學習預測本質，而非內建「[🏛️符號流](03----symbolic_ai.zh-hant.md)」AI 知識庫，直觀地解釋為何模型生成可能產生「幻覺」，而非查證事實。
- ❌ **解釋缺失部份**：
    - 🤔 **湧現能力**：難以解釋模型如何展現超越簡單預測的複雜推理、摘要等能力。誤以為僅是「表層模仿」，忽略其**深層語意建模**能力。
    - 🪞 **內部表徵**：未觸及模型形成複雜語言與概念內部表徵的「如何」運作。

此說法突顯 LLM 的 **[生成邏輯](06-05-analysis_generative.zh-hant.md)** 與 **[機器學習](04-05-machine_learning_models.zh-hant.md)** 依靠海量文本的面向，但未能充分說明**語境理解**、**推理**與**創造性輸出**的潛力機制。

## 🔄歷史演進🗿

`大語言模型` 發展史，是**深度學習**不斷朝向**語言理解**與**生成極限**邁進的歷程，歷經幾次關鍵的**技術革命**和**規模突破**，最終從經典自然語言處理（NLP）演進為當代的 **[生成式 AI](06-05-analysis_generative.zh-hant.md)**。

- 📜 **基礎奠定期（2013–2017）** ➠ **詞向量**（Word Embeddings，如 Word2Vec、GloVe）的出現，標誌著語言模型從純粹的符號表示進入**向量空間**。隨後的 **RNN**（循環神經網路）和 **LSTM** 等序列模型成為主流，讓模型開始處理上下文依賴性，為語言理解奠定了神經網絡的基礎。
- 🌌 **注意力機制與轉換器革命（2017）** ➠ **轉換器（Transformer）** 架構的發表 [@Vaswani2017-attention]，徹底改變了序列處理方式。它引入了**自注意力機制**（Self-Attention），使得模型能**同時**捕捉長距離依賴關係，克服了 RNN 的效率瓶頸，成為所有現代 LLM 的核心基石。    
- 🔮 **預訓練模式確立（2018–2020）** ➠ **BERT**、**GPT-2** 等模型的誕生，確立了 **「預訓練 + 微調」** 的範式。模型透過在海量**未標記文本**上進行**自我監督學習**（Self-Supervised Learning），從而學習到通用的語言知識，這極大地提升了模型處理下游 NLP 任務的表現。    
- 🔼 **規模與突現能力（2020–2022）** ➠ 隨著模型規模（參數數量）不斷擴大，達到數百億甚至數千億級別（如 GPT-3、PaLM），模型開始展現出「**突現能力**」（Emergent Abilities）。這些能力包括**情境學習**（In-Context Learning）和**複雜推理**，標誌著 LLM 從語言工具轉變為**通用認知輔助工具**。   
- 🤝 **對齊與人性化（2022–至今）** ➠ **人類回饋強化學習**（RLHF） 成為主流對齊技術。透過這個階段，模型（如 ChatGPT、GPT-4）的輸出被引導至更符合人類**偏好、價值觀和安全性**，從而在人機互動和部署應用方面取得巨大成功，使其能更廣泛地應用於實際生活與商業場景。    
- 🌐 **多模態與具身智慧（2023–至今）** ➠ `大語言模型` 開始與圖像、聲音等其他模態數據結合（如 Gemini、GPT-4V），發展出**多模態 LLM**。同時，結合**具身智慧**（Embodied AI）的研究，正在探索讓 LLM 不僅能理解語言，還能與物理世界進行「**行動**」互動，向更具通用性的 AI 發展。[bibtex reference required]

由此可見，`大語言模型` 的歷史演進是**深度學習**技術、**計算規模**和**數據可用性**共同作用的結果，其核心突破是 **轉換器架構** 和 **自我監督學習**，為當代 AI 系統提供了語言理解與推理基礎。
