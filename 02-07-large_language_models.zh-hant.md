---
tags:
  - 基礎模型
  - 生成模型
  - 湧現能力
  - RLHF
---
# 😵‍💫🧞‍♀️大語言模型 {#sec-large-language-models}

`大語言模型`（Large Language Models, LLMs）因為 2022 年底代表性案例 [LLM聊天機器人](04-02-llm_chatbots.zh-hant) **ChatGPT**的迅速普及，不僅重燃了人們對人工智慧（AI）的熱情，甚至引發了對通用人工智慧（[AGI](02-04-agi.zh-hant)）的遐想。

為了闡明`大語言模型`，已有幾類 ❝腦補❞ 心智模型假說，解釋其功能及運作：

- 🎞🤯 **巨型自動完成機**（Giant Autocomplete Machine）：LLM 好比文本預測「極致自動完成」仙，能超越自動完成系統猜中下一個詞。
- 🗺️🧭 **巨型統計地圖**（Giant Statistical Map）：LLM 如同詞彙「路徑生成」神，能在高維語意地圖按最可能路徑前行，完成神回應。
- 🗜️😵‍💫 **網際網路文本有損壓縮**（Lossy Compression of Internet Text）：LLM 如「整個網路的海量文本」模型參數壓縮檔，因捨棄細節有損所以難免「產生幻覺」。
- 🎭🧞‍♀️ **人機腦補語言賽局**（Mutual Mental Fill-in Language Game）：LLM 好比聊天「對話藝術」精，能流暢多輪對話贏得使用者信任（❝腦補❞雙贏賽局），填補對話甚至心靈空缺。

本條目在分述這些 ❝腦補❞ 心智模型假說後，會就其**模組化生產力**、**常見類型與任務**、**歷史演進**做介紹。

## 🎞巨型自動完成機🤯

🏷️ **解釋**：LLM 本質上是一個極度先進的 `巨型自動完成機`（Giant Autocomplete Machine），為了要**預測**最有可能出現的下一個詞，LLM 基於海量文本資料中習得語言的統計模式，並據此[生成](06-05-analysis_generative.zh-hant.md) 連貫文本，參與流暢對話。這比喻說法由**Grant Sanderson** 等人推廣，突顯使用者感知到的是 LLM [模仿人類溝通](01-01-Turing_Test.zh-hant.md)的「智慧」[@Sanderson2023-gpt-visual-intro;@Manning2022-understanding-reasoning-with-llms]。

- 🎯 **解釋較準部份**：
    - 🤯 **簡單易懂**：用過當代搜索界面有「自動完成」或「自動補完」的使用者，能將LLM簡單理解為更強大的「接話器」。
    - 🎞 **核心機制**：精準捕捉模型根本的 [機率性關聯](04-01-probabilistic_association.zh-hant) 本質，與依序生成詞彙的過程。
    - ⚠️ **凸顯限制**：突顯其「[🌀統計流](04----statistical_ai.zh-hant.md)」機器學習預測本質，而非內建「[🏛️符號流](03----symbolic_ai.zh-hant.md)」AI 知識庫，直觀地解釋為何模型生成可能產生「幻覺」，而非查證事實。
- ❌ **解釋缺失部份**：
    - 🤔 **湧現能力**：難以解釋模型如何展現超越簡單預測的複雜推理、摘要等能力。誤以為僅是「表層模仿」，忽略其**深層語意建模**能力。
    - 🪞 **內部表徵**：未觸及模型形成複雜語言與概念內部表徵的「如何」運作。

此說法突顯 LLM 的 **[生成邏輯](06-05-analysis_generative.zh-hant.md)** 與 **[機器學習](04-05-machine_learning_models.zh-hant.md)** 依靠海量文本的面向，但未能充分說明**語境理解**、**推理**與**創造性輸出**的潛力機制。

***
## 🗺️巨型統計地圖🧭

🏷️ **解釋**：LLM 也可以被視為一張「巨型統計地圖」（Giant Statistical Map）。在這張多維度的語意地圖上，每個詞彙、概念與語境都被映射為一個 [向量空間](04-07-vector_space.zh-hant.md) 中的座標點。地圖上，意義相近或在相似語境中出現的詞彙，彼此的位置會比較接近。當輸入提示時，模型會找到詞彙的對映座標，然後依統計學上最可能、最連貫的在圖上繪製出「導航路徑」，沿途生成詞彙，最終形成回應。這個比喻由 **Christopher Manning** 等學者提出，突顯 LLM 的核心在於 **語意結構** 的 **捕捉與導航** [@Manning2022-understanding-reasoning-with-llms]，比喻稍抽象但貼近 LLM 處理語言的底層數據運作。

- 🎯 **解釋較準部分**：
    - 🌌📍 **向量嵌入**：正確揭示 **向量嵌入**（vector embeddings）與 **語意相似性** 的「[向量空間](04-07-vector_space.zh-hant.md)」為LLM 的基礎核心概念。
    - 🧭🔗 **關聯性推理**：有助於解釋模型如何理解概念之間的關係，而不僅是單詞的逐一拼接。
    - 🗺️📐 **結構化知識**：提供了一種視覺化方式，將知識成多維空間「地圖」的結構表徵。這呼應 LLM 的「**世界模型假設**」（World Model Hypothesis），即認為模型在訓練過程中，必須**內在地構建**一個抽象的世界表徵才能高效預測文本[@Glaeser2024-worldmodel]。
- ❌ **解釋缺失部分**：
    - ❓😵‍💫 **直觀性不足**：對非技術背景的讀者而言，這個比喻較抽象，不如「自動完成」那樣容易理解。
    - 🎲🚶 **逐步生成**：儘管它解釋了「路徑導航」，但未能清楚展示 LLM 如何透過機率分布逐步生成詞元（token），以及為何會選取特定路徑。

此說法側重於 LLM 的 **知識表徵** 及  **語意導航** 能力，將其比擬為一個能理解語意關係、進行抽象推理的「語言地圖」或「知識導航」系統。然而，它未能說明 LLM 在生成過程中的 **序列性** 與 **隨機性**，因此需要與其他比喻補充。


## 🗜️網際網路文本有損壓縮😵‍💫

🏷️ **解釋**：LLM 可以被視為一種「網際網路文本有損壓縮」。它將整個網路的龐大文本資料進行「壓縮」，濃縮成數十億甚至上千億的參數。由於壓縮過程必然捨棄細節，因此模型在生成時可能「補齊」缺失資訊，導致所謂的「幻覺」（hallucination）。這個比喻由 **Andrej Karpathy** 在其文章與演講中提出 [@Karpathy2023-llm-fullstack]。

- 🎯 **解釋較準部分**：
	- 🤖📦 **訓練本質**：準確描述了 LLM 的訓練本質，即從海量數據中提取並編碼核心模式。
	- 🪢🧠 **記憶與遺忘**：解釋了模型為何會「產生幻覺」或無法記住特定事實，因為資訊在壓縮過程中被部分遺失。    
	- 📐📏 **規模體現**：形象地呈現了龐大的訓練數據量與其相對「輕巧」的模型大小之間的落差。
- ❌ **解釋缺失部分**：
    - 🎭🧞‍♀️ **能力來源**：這個比喻無法解釋模型如何從單純的壓縮中，**湧現**出創造性寫作、程式編寫等新穎能力，無法具體說明「**突現能力假設**」（Emergent Abilities Hypothesis）的核心： 文本規模的量變，是如何導致能力的質變，使模型具備未經明確訓練的能力。
    - 🧑‍💻🌌 **技術抽象**：對非技術背景者而言，這個比喻較難直觀理解。

此說法突顯 LLM 的 **工程學**角度，將 LLM 視為一個**數據壓縮與知識編碼**的產物，強調知識來源與固有的不精確性，但這比喻未能描述或解釋 LLM 在語意建模與推理上的**湧現能力**。

## 🎭人機腦補語言賽局🧞‍♀️

🏷️ **解釋**：LLM 也可以被理解為一種「人機腦補語言賽局」（Mutual Mental Fill-in Language Game）。它是否真正「理解」語言並非重點，而是能夠流暢地參與人類的語言賽局。在對話中，LLM 透過生成流暢、具說服力的語言，誘發使用者的❝腦補❞，讓人誤以為機器「懂」自己。這種互動甚至能在文字層面上通過圖靈測試，也呼應了 Bender 等人提出的「**隨機鸚鵡**」（stochastic parrots）隱喻：模型雖然能複製與重組語言，但未必真正理解語言或世界 [@Bender2021-stochastic-parrots; @Weidinger2022-ethical-risks]。

- 🎯 **解釋較準部分**：
	- 🗫🎲 **互動本質**：突顯 LLM 在**對話流暢性與互動策略**上的優勢，並揭示人類在語言賽局中也會進行❝腦補❞。    
	- 🎭🧞‍♀️ **能力展示**：這個比喻呼應「**突現能力假說**」（Emergent Abilities Hypothesis），透過對話流暢的結果，展現 LLM 的質變能力。    
	- 🎭🗪 **圖靈測試**：強調 LLM 在文字互動中能通過圖靈測試。    
	- 😘💞 **影響力**：指出 LLM 的流暢性與說服力能**引導**、**誘導**甚至**塑造**使用者的信任與判斷，可能討好或迎合使用者，並彰顯模型**訓練者**與**使用者**之間的**不對稱權力**關係。這語言賽局的比喻提醒我們：LLM 的「智慧」部分來自人類的參與與腦補，而未必是模型本身對世界的理解。
- ❌ **解釋缺失部分**：
	- 🎭🧞‍♀️ **意圖與情感**：這個比喻無法解釋模型是否具備**真實意圖或情感**，僅能描述其對使用者意圖與情感的影響。同時，其**哲學性**與**行為主義**視角未能區分**深度學習**與**強化學習**在塑造 LLM 流暢性與「心智」意圖上的細微差異。    
	- ❓😵‍💫 **能力機制**：雖能展示「**突現能力假說**」並說明互動機制，但無法解釋模型內部的運作原理。

此說法突顯 LLM 的 **社會互動**與**語境適應力**，並揭示其背後的**不對稱權力**關係。然而，它無法解釋 LLM 的「心智」或「意圖」是否真實存在，以及突現能力的內在運作機制。雖然有提出 LLM 訓練者間接形塑使用者行為的假說，但尚未提供清晰的因果解釋。

***

## 🔂模組化生產力🏭

`大語言模型` 強大能力一套技術透過**模組化**和**工具化**的方式將智能輸出到多個應用層面，極大地提高了生產力。

其關鍵組成技術依 LLM 的角色，可按**基礎架構**、**訓練範式**、**功能擴展**與**部署優化**四大模組進行劃分：

* 🛠️ 基礎架構與表示層：
	* 🧠 **轉換器與注意力機制**：以 **轉換器** （Transformer）結構為骨幹，透過**自注意力**（Self-Attention）機制應對了序列處理中的長距離依賴問題，並允許**並行序列處理**，標誌**深度學習**重大突破。
	* 🧩 **詞元化與向量嵌入**：採用 **BPE/Unigram** 等方法將文本分解為詞元（tokens），並將其映射到**向量嵌入**，還利用如**位置編碼**等精確捕捉序列中的**語義與順序資訊**
	* 🧮 **混合專家與稀疏路由**：利用 **混合專家**（MoE）架構，在處理不同類型的輸入時，動態地激活模型中**稀疏的專家子網路**。這極大地提高了模型的**參數效用**和**可擴展性**，同時平衡了效能與訓練成本。
* 🔮 核心訓練與對齊範式：
	* 🦾 **自我監督預訓練**：以「下一詞預測」或「遮罩語詞」等目標，在海量**未標記文本**上進行訓練，使模型學習到可遷移的**通用語言結構與分佈表徵**。
	* 🧰 **監督式微調與偏好對齊**：首先透過少量**人工示範**進行**監督式微調**（SFT）來確立任務執行能力；隨後利用 **RLHF/RLAIF** 訓練**偏好模型**，將模型輸出與人類的**價值觀、安全邊界**和**指令意圖**進行對齊。
	* 🧱 **參數高效微調（PEFT）**：採用 **LoRA/Adapters/Prefix-Tuning** 等技術，僅微調少量額外參數，便能在極低成本下快速**客製化領域模型**或**適應新任務**，同時保留模型的基礎能力。
* 🔀 功能與推理擴展：
	* 🔀 **涌現推理與思維鏈**：利用 **Chain-of-Thought**（CoT）、**Self-Consistency**、**Program-of-Thought** 等技術，促使模型**外化中間推理步驟**和**自我糾錯**，從而顯著強化模型處理複雜任務的**邏輯推理能力**。
	* 🧲 **檢索增強生成**：結合**向量資料庫**對外部權威知識（如文件、API 結果）進行檢索（RAG），並將結果動態注入 LLM 的脈絡上下文，**降低幻覺**並大幅**提升輸出的事實性和可驗證性**。
	* 🪝 **工具調用與函式呼叫**：透過**結構化輸出**（例如 JSON、函式呼叫），讓 LLM 能夠觸發並利用**外部計算工具**（如搜尋引擎、資料庫查詢、API、MCP 等等），將模型從單純的「語言生成」升級為「**任務協作**」能力。
	* 🌈 **多模態與知識結構**：耦合**圖像/音訊/影片編碼器**與**語言解碼器**，使模型能理解和生成多模態內容；同時結合**知識圖譜或結構化資料**，擴展模型的**語義理解與事實推理邊界**。
* 🛡️部署與可信賴性：
	* 🧭 **脈絡工程與工作記憶**：透過提示**模板化**、**角色/指令分層**、**檔案分段編排**和**會話記憶管理**，提升對話的**長上下文可控性**與**穩定性**。
	* 🧪 **評估與安全護欄**：實施**多維度評測**（涵蓋任務表現、事實性、公平性、推理能力）、**紅隊測試**、**輸入/輸出過濾**和**內容政策**，以建立風險控管機制，確保 LLM 應用的**可用性與可信賴性**。
	* ⚙️ **推理優化與部署**：透過**量化**、**模型剪枝**、**KV-Cache** 管理、**張量並行/流水線並行**等技術，提升模型在生產環境中的**延遲和吞吐量**，並透過服務編排管理模型與外部資源。

綜合來看，`大語言模型` 的模組化技術堆疊，讓其從單純的語言生成器，演化為可被調用、可被擴展、可被部署的「智能基礎設施」。這些模組不僅確立了 LLM 的核心能力，也為其在不同場景下的應用提供了靈活性與可重用性。

## ▶️常見類型與任務🎯

`大語言模型` 的模組化生產力主要體現為將其核心能力（推理、生成、工具調用）嵌入到特定的工作流程中，應用類型可分為四大類：

- **資訊管理與知識獲取** (Information & Knowledge Management)：主要依賴 LLM 的**檢索增強生成 (RAG)** 和**語義理解**能力，將非結構化數據轉化為可操作的知識。    
    - 🗂️ **文件助理與知識中台**：利用 **RAG/向量庫** 打造企業級知識庫，實現可查、可引、可追溯的文檔處理。可支援**摘要、比對、引用生成**與**合規審閱**等具體任務。        
    - 🔍 **分析與決策輔助**：利用 **涌現推理（CoT）** 和**自我一致性**生成高質量分析。可用來生成分析報告、指標解讀、情境推演，並輔助**數據查詢**提高決策品質。        
    - 🧬 **垂直領域助理**：利用 **參數高效微調（PEFT/LoRA）** 快速客製化模型。實現**法務條文檢索**、**醫療指引摘要**、**研究文獻綜述**、**教育教案編排**等專業任務。        
- **流程自動化與結構化數據** (Process Automation & Structure)：側重於利用 LLM 的**結構化輸出**和**工具調用**能力來優化業務流程。    
    - 🧾 **結構化輸出自動化**：將非結構化文本轉換為 **JSON/表單/票據**。用於串接**審批、工單**與**資料管線**，降低人工處理成本。        
    - 🔄 **流程編排與智能體**（Agent）：以 **工具調用** 結合 **思維鏈** 進行高階任務分解與協作。透過 **MCP/API** 連接外部系統，實現**分工、回報與自我監督**的複雜跨工具任務。        
    - 🧭 **脈絡工程工作台**：將**提示模板、角色卡、記憶策略**與**評估面板**工具化。形成可重用的「提示—檢索—工具」三位一體管線，提升**長上下文可控性**。        
- **內容與人機互動** (Content & Human-Computer Interaction)：主要圍繞 LLM 的**生成、對齊**和**多模態**能力，優化與用戶之間的溝通和內容產出。    
    - 💬 **客服與對話代理**：結合**多輪對話、意圖識別**與**工具呼叫**。覆蓋問答、故障排除、**交付追蹤**與**個人化推薦**等任務。        
    - 🎨 **內容生成與在編**：利用 **多模態** 與**脈絡工程**進行精準生成。用於文案、企劃、腳本與多模態素材的創作，並以**版型/風格提示**維持品牌一致性。        
    - 🛠️ **開發者協作與運維**：利用 LLM 的**代碼生成**和**函式呼叫**能力。執行**程式草稿、重構、測試生成**；並透過函式呼叫執行**診斷、日誌分析**與**告警處理**。        
- **系統韌性與企業化部署** (System Resilience & Enterprise Deployment)：關注如何確保 LLM 應用的**安全性、可靠性**和**持續迭代**。    
    - 📑 **合規與風險控管**：結合 **評估與安全護欄** 模組。執行**條款比對、敏感內容檢測**與**解釋性回覆**，建立可稽核的審查流水線。        
    - 🚀 **產品化與 A/B 疊代**：結合**線上指標與離線評測**。快速試驗**提示/檢索/路由策略**，以持續優化用戶體驗與轉化率。        
    - 🧪 **評測基準與紅隊場景庫**：建立**任務集、對抗案例**與**安全測試場景**。常態化進行**回歸測試**與**風險掃描**，以提升 LLM 應用的可用性與韌性。

接下來，若要理解這些模組如何逐步形成並推動 AI 的突破，就需要回顧 `大語言模型` 的 **歷史演進**，從早期詞向量到轉換器革命，再到今日的多模態與具身智慧。

## 🔄歷史演進🗿

`大語言模型` 發展史，是**深度學習**不斷朝向**語言理解**與**生成極限**邁進的濃縮歷程，歷經幾次關鍵的**技術革命**和**規模突破**，最終從經典自然語言處理（NLP）演進為當代的 **[生成式 AI](06-05-analysis_generative.zh-hant.md)**。

- 📜 **基礎奠定期（2013–2017）** ➠ **詞向量**（Word Embeddings，如 Word2Vec、GloVe）的出現，標誌語言模型從純的符號表示進入 **[向量空間](04-07-vector_space.zh-hant.md)**。隨後的 **RNN**（循環神經網路）和 **LSTM** 等序列模型成為主流，讓模型開始處理脈絡上下文依賴性，為語言理解奠定了 **[神經網路](04-03-neural_networks.zh-hant.md)** 的基礎。
- 🌌 **注意力機制與轉換器革命（2017）** ➠ **轉換器（Transformer）** 架構的發表 [@Vaswani2017-attention]，徹底改變了序列處理方式。它引入了**自注意力機制**（Self-Attention），使得模型能**同時**捕捉長距離依賴關係，克服了 RNN 的效率瓶頸，成為所有現代 LLM 的核心基石。
- 🔮 **預訓練模式確立（2018–2020）** ➠ **BERT**、**GPT-2** 等模型的誕生，確立了 「**預訓練 + 微調**」範式。模型透過在海量**未標記文本**上進行**自我監督學習**（Self-Supervised Learning），從而學習到通用的語言知識，這極大地提升了模型處理下游 NLP 任務的表現。
- 🔼 **規模與突現能力（2020–2022）** ➠ 隨著模型規模（參數數量）不斷擴大，達到數百億甚至數千億級別（如 GPT-3、PaLM），模型開始展現出「**突現能力**」（Emergent Abilities）[@Wei2022-emergent]。**思維鏈**（Chain-of-Thought, CoT）的關鍵技術成果，即透過引導模型輸出中間推理步驟，極大地提升了 LLM 在複雜數學、邏輯推理上的表現。這些能力標誌著 LLM 從語言工具轉變為**通用認知輔助工具**。
- 🤝 **對齊與人性化（2022–至今）** ➠ **人類回饋強化學習**（RLHF） 成為主流對齊技術。透過這個階段，模型（如 ChatGPT、GPT-4）的輸出被引導至更符合人類**偏好、價值觀和安全性**，從而在人機互動和部署應用方面取得巨大成功，使其能更廣泛地應用於實際生活與商業場景。
- 🌐 **多模態與具身智慧（2023–至今）** ➠ `大語言模型` 開始發展出**多模態 LLM**，與圖像、聲音等其他模態數據結合（如 Gemini、GPT-4V）[@OpenAI2023-gpt4]。同時，結合 **[具身智慧](08----embodied_ai.zh-hant.md)**（Embodied AI）的研究，正在探索讓 LLM 不僅能理解語言，還能與物理世界進行「**行動**」互動，向更具通用性的 AI 發展 [@Driess2023-PaLME]。

由此可見，`大語言模型` 的歷史演進是 **深度學習** 技術、**計算規模** 和 **數據可用性** 共同作用的結果，其核心突破是 **轉換器架構** 和 **自我監督學習**，為當代 AI 系統提供了語言理解與推理基礎，並產出**多模態 LLM** 及 具身智慧 等相關創新。

## 📦 延伸：AI 發展假說

以下有五個 AI 發展假說，請參照上述`大語言模型`的 ❝腦補❞ 心智模型假說，說明哪一種 AI 發展假說最具說服力，申論之。

- 💥**[AI 對齊崩潰假說](glossary.zh-hant.md#ai-alignment-collapse)**：隨著 AI 能力提升，若無法持續確保其行為與人類價值對齊，將導致追求衝突目標、產生有害行為，最終引發社會決策、經濟與安全體系的**系統性失序與混亂**。
- 🌐 **[AI 公共財假說](glossary.zh-hant.md#ai-commons-hypothesis)**（AI Commons Hypothesis）：主張 AI 應被視為**共享資源**，透過**開源模型、開放資料**與**社群治理**，推動技術的去中心化發展與民主化，以避免少數權力壟斷。
- 👑 **[AI 帝國假說](glossary.zh-hant.md#ai-empire-hypothesis)**（AI Empire Hypothesis）：預測**算力、資料與演算法**將集中於少數國家或超級平台，形成類似「帝國」的支配格局，導致全球創新單一化與**治理不對稱**的風險。
- ⚔️ **[AI 部落化／碎片化假說](glossary.zh-hant.md#ai-tribalization-fragmentation)**（AI Tribalization / Fragmentation Hypothesis）：認為 AI 發展將呈現**多極化、碎片化**格局，不同意識形態群體建立各自的 AI 生態與標準，導致**全球治理失序與標準分裂**。
- 🚰 **[AI 公用事業假說](glossary.zh-hant.md#ai-utilities-hypothesis)**（AI Utilities Hypothesis）：主張 AI 將如同電力或網路一樣，成為**普及、隱形、無所不在的社會基礎設施**，並由政府、企業與社群共同監管，以確保公平取用與安全性。

***

## 👉接下來🪸

- ⮦🚦 探究 [第陸篇 ❖](06----analytics_decisions.zh-hant.md)　**分析與決策 6 點**，探索 `LLM` [生成式 AI](06-05-analysis_generative.zh-hant.md) 對分析與決策的影響。
- ⮦🚥 探究 [第拾篇 🌉](10----ai_engineering.zh-hant.md)　**AI工程**，探索 `LLM` 的相關實踐及應用：
	* **10.1** 🌉🔗🌐 [API與MCP](10-01-API_MCP.zh-hant.md)（API/MCP）
	* **10.2** 🌉🤖🚨 [智能體可靠性與評估](10-02-agent_reliability_evaluation.zh-hant.md)（Agent Reliability & Evaluation）
	* **10.3** 🌉❔📌 [提示工程](10-03-prompt_engineering.zh-hant.md)（Prompt Engineering）
	* **10.4** 🌉🔗📒 [知識驅動生成（RAG）](10-04-retrieval_augmented_generation.zh-hant.md)（Retrieval-Augmented Generation）
	* **10.5** 🌉🪟🧭 [脈絡工程](10-05-context_engineering.zh-hant.md)（Context Engineering） 
	* **10.6** 🎁🌱🚀 [AI 產品經理](10-06-AI_PM.zh-hant.md)（AI Product Management）
- ⮦🚦 探究 [第肆篇 🌀](04----statistical_ai.zh-hant)　**統計流 AI**的其它條目，評估自己可不可以說明 `LLM` 和它們的關係，如下所述：
	- **🌀🎲🌿 [機率性關聯](04-01-probabilistic_association.zh-hant)**：`LLM`型透過**序列預測的訓練**，學習輸入文本與輸出詞元之間的**機率性關聯**，是其生成連貫文本的根本。
	- **🌀🧞‍♀️🗪 [LLM聊天機器人](04-02-llm_chatbots.zh-hant)**：本身就是一種複雜的`LLM`應用，利用龐大的參數和海量數據進行訓練，以實現自然語言的**理解與生成**。   
	- **🌀🪢🧠 [神經網路](04-03-neural_networks.zh-hant)**：現代 `LLM` 最為強大和流行的一類**神經網路**骨幹，是**轉換器架構**（Transformer），尤其是在處理**長距離依賴**和**大規模預訓練**方面。     
	- **🌀🛠️🤏 [特徵工程](04-04-feature_engineering.zh-hant)**：現代 `LLM` 的**注意力機制**是允許模型在處理序列時**加權關注**不同部分的輸入的特徵工程，是實現精確**語境理解**的關鍵。  
    - **🌀🌐🔗 [大語言模型網組合](04-06-llm_webassembly.zh-hant)**：**大語言模型網組合**的實現，依賴於高效能的 `LLM` 在網際網絡瀏覽器環境中完成如**推理引擎**等任務。 
    - **🌀🌌▦ [向量空間](04-07-vector_space.zh-hant)**：`LLM`在**向量空間**中進行操作，將詞彙和概念轉換為**向量表示**（Embeddings），並在此空間中尋找**語義模式**和進行**類比推理**。

