---
title: "🌀🎲🌿 機率性關聯"
tags:
- 統計流
- 機率
- 歸納
- 貝氏網路
- 機器學習
- 大型語言模型
- 思維鏈
- 思維鏈提示法
- 思維鏈解碼法
---
`機率性關聯`指在不確定性環境下，根據統計資料推估事件之間的關聯性與發生機率。它不追求絕對的因果關係，而是關注「在某些條件下，某事件發生的可能性有多高」。例如，根據過去資料，我們可能發現「在雨天，外送訂單量增加的機率為 80%」，這就是一種機率性關聯。這種思維方式是**統計流 AI** 的核心，特別適用於處理大量、雜訊多、結構不明的資料。

在「統計流 AI」中，機率性關聯是建構模型的基石。無論是**貝式網路**（Bayesian Networks）、**隱馬可夫模型**（Hidden Markov Models），還是現代的機器學習演算法，幾乎都依賴機率性關聯來進行**預測**與**分類**。舉例來說，在**推薦系統**中，AI 會根據使用者過去的行為，計算某商品被喜歡的機率；在語音辨識中，系統會根據語音特徵判斷某字詞出現的可能性。這種「根據機率做決策」的能力，使得統計流 AI 能夠在複雜、動態的環境中表現出高度適應性。

## 💡理解世界的視角

對人類學習者而言，機率性關聯不只是數學公式，而是一種消化世界各種信息的處理方式。它教我們如何在不確定中尋找**模式**、在雜訊中提取**訊息**。在 AI 領域，它是讓機器「**懂得預測**」的關鍵；在人類社會，它則是讓我們「**懂得風險**」的工具。

## ⚡️當代實例－思維鏈

`思維鏈`是一種讓現代**大型語言模型**將「分解問題，逐步推導」以獲得更精準答案的技術。它鼓勵模型在給出最終答案前，先生成一系列中間的**推理**步驟。

### 🗣️🌿兩種實現方式

主要可分為兩種實現方式：**思維鏈提示法**（CoT Prompting）與**思維鏈解碼法**（CoT Decoding）：

|特性|**思維鏈提示法（CoT Prompting）**|**思維鏈解碼法（CoT Decoding）**|
|---|---|---|
|**實現方式**|提示工程（Prompt Engineering）|解碼策略（Decoding Strategy）|
|**控制層級**|外部、使用者層級|內部、演算法層級|
|**效果穩定性**|較不穩定|較為穩定，精確度更高|
|**實作難度**|低|高|
|**運算成本**|低|高|
|**適用情境**|輕量級應用、快速原型驗證|追求高精準度、高可解釋性的關鍵應用|

**機率性關聯**仍是這兩種方式的核心運作機制。大型語言模型並非像**形式邏輯**般進行演繹推理，而是在海量數據中學會語言符號之間的統計關聯。思維鏈技術鼓勵模型在給出最終答案前，先生成一系列中間的**推理**步驟，這些中間步驟用自然語言表達思緒去尋找最匹配的思維過程，從而表現出類似於邏輯推理的能力。

* 🗣️🧠 思維鏈提示法（CoT Prompting）：是**機率性脈絡上下文**
	* 提示法之所以有效，是因為提示詞「**一步一步來思考**」（Let's think step by step）創造了一個新的**機率性脈絡上下文**；
	* 模型基於習得的大量邏輯性的（解題）文本，它會偏向於生成看起來有邏輯順序的詞元，實現一種高階的**模式匹配**與**機率性聯想**整合。
* 🌿⚙️ 思維鏈解碼法（CoT Decoding）：是最佳的**機率路徑**選取
	* 解碼法之所以有效，是因為思考序列的多條可能的路徑去累積**機率值**；
	* 模型以演算法搜尋最正確的結論，它會偏向在龐大的**向量空間**中，尋找與「正確答案」相關聯性最高的路徑。


### ⚙️機率性關聯的關鍵作用

**機率性關聯**仍是這兩種方式的核心運作機制。大型語言模型並非像**形式邏輯**般進行演繹推理，而是在海量數據中學會語言符號之間的統計關聯。

- **🧠 思維鏈提示法**之所以有效，是因為提示詞「**一步一步來思考**」創造了一個新的**機率性脈絡上下文**；模型基於習得的大量邏輯性文本，會偏向於生成看起來有邏輯順序的詞元，實現一種高階的**模式匹配**與**機率性聯想**整合。
    
- **⚙️ 思維鏈解碼法**則是在演算法層級，透過累積**機率值**來搜尋多條可能的思考序列，並在龐大的**向量空間**中，尋找與「正確答案」相關聯性最高的路徑，最終選取最優解。
    

簡言之，思維鏈技術並沒有改變其**歸納**統計本質，而是巧妙地運用技巧，讓模型能夠更有效率地利用其內在的**機率性關聯**。這使模型的機率性運作過程更具結構性和透明度，從而提高答案的準確性並增強其可解釋性。

* 🗣️🧠 思維鏈提示法（CoT Prompting）：是**使用者要求**模型去思考
	* 直接告訴模型「**一步一步來思考**」（Let's think step by step），或者提供一個包含逐步推導的範例。模型會模仿這種模式，在生成最終答案之前，先輸出詳細的思考過程。
* 🌿⚙️ 思維鏈解碼法（CoT Decoding）：是**系統演算法**引導模型去思考
	* 解碼**演算法**會引導模型，使其在每個生成步驟都朝著正確的邏輯方向前進。例如，**樹狀思維鏈**（Tree-of-Thought）會像樹枝一樣分岔，探索多條可能的思考路徑，並評估哪條路徑最可能通往正確答案，最終選取最優路徑。

簡言之，思維鏈技術並沒有改變其**歸納**統計本質，而是巧妙地運用技巧，讓模型能夠更有效率地利用其內在的**機率性關聯**，從而表現出類似於邏輯推理的能力。

儘管如此，思維鏈使模型的機率性運作過程更具結構性和透明度，從而提高答案的準確性並增強其可解釋性。其推理過程底層運作仍是基於**機率性關聯**，而非形式邏輯。

掌握機率性關聯，就是進入統計流 AI 世界的第一步 🎲。

***

## 👉 接下來 

- 區分**機率性關聯**與**形式邏輯**在**因果推論**上的核心差異。前者基於**歸納**，探討「機率性關聯」；後者基於**演繹**，追求絕對的「因果關係」。
- 探究[第肆章 🌀](04----statistical_ai.zh-hant) **統計流 AI**（Statistical AI）的其它條目，評估自己可不可以說明**機率性關聯**和它們的關係，如下所述：
	- **🌀🧞‍♀️🗪 [LLM聊天機器人](04-02-llm_chatbots.zh-hant)**：這類應用是基於**大語言模型**的，而其核心運作原理就是透過**機率性關聯**來生成對話。   
	- **🌀🪢🧠 [神經網路](04-03-neural_networks.zh-hant)**：神經網路透過調整權重與偏置，來學習資料中的**機率性關聯**，並以此進行預測與分類。     
	- **🌀🛠️🤏 [特徵工程](04-04-feature_engineering.zh-hant)**：這個過程從原始數據中提取並轉換出有意義的**特徵**，是為了讓**機器學習模型**能更有效地捕捉到潛在的**機率性關聯**。     
	- **🌀🤖📦 [機器學習模型](04-05-machine_learning_models.zh-hant)**：這是一個通稱，絕大多數的機器學習模型，其建構目的就是為了從數據中發現、建模並利用**機率性關聯**來進行預測或決策。     
	- **🌀🌐🔗 [大語言模型網組合](04-06-llm_webassembly.zh-hant.md)**：作為統計流 AI 的集大成者，大語言模型的**生成**能力完全基於海量資料學到的**機率性關聯**。     
	- **🌀🌌▦ [向量空間](04-07-vector_space.zh-hant)**：**向量空間**是**機率性關聯**的數學體現，它將語言符號轉換為數值向量，並透過向量間的距離來表示它們之間的**關聯性**。