---
title: 語言賽局🗣️🎲
tags:
- 維根斯坦
- 語言哲學
- 符號主義
---
`語言賽局`（又稱 `語言遊戲`，Language Games）是路德維希・維根斯坦（Ludwig Wittgenstein）晚期哲學的核心概念。他透過這個概念重新界定語言的意義，並提出：

> 🗣️🎲 「一個詞的意義，就是它在語言中的用法。」  
> ——《哲學探究》§43

維根斯坦主張，語言的意義並非來自於靜態符號的編碼，而是**一種動態、嵌入於具體情境與生命形式（Forms of Life）的社會性實踐**。

## ㉄ 意義如何生成？

儘管維根斯坦未曾直接探討人工智慧，其語言賽局框架以下共同關心問題提供視角：

> 🗣️🎲 意義是如何生成的？

維根斯坦認為，語言的意義並非來自詞彙本身，而是嵌於「生命形式」——即人類的文化、習俗、情境與互動方式。

維根斯坦的語言用法主張突顯具體情境與「賽局」：每一次的發言，無論是詢問、道歉、開玩笑，都承載著隱含的**社會期待**、**利害交換**與**博弈格局**，共同構成一場場互動中的「賽局」。

### 🎮 兩場遊戲：維根斯坦 vs. 圖靈

維根斯坦的「語言賽局」與圖靈的「模仿遊戲」都以「遊戲」作為比喻框架，但兩者的哲學意涵截然不同，反映了對「意義」和「智能」的根本分歧：

| 遊戲類型  | 語言賽局（維根斯坦）  | 模仿遊戲（圖靈） |
| ----- | ----------- | -------- |
| 🧭 本質 | 開放、參與式      | 封閉、表演式   |
| 🧬 根基 | 紮根日常生活與生命形式 | 技術性模擬    |
| 🎯 目標 | 真正理解與互動     | 模擬理解     |
| 🧠 對象 | 人類語言使用者     | 機器模仿者    |

圖靈的模仿遊戲是判斷機器是否具備智能的**有限測試**：只要機器能透過文字對話，表現出與人類無法區分的行為，即被認為通過測試。這是一種關於**行為表現**的檢驗，關乎「看起來像」智能。

相對地，維根斯坦的「語言賽局」則深植於語言的**社會性**與**脈絡性**。它強調語言的意義不是來自於符號本身，而是來自於人們在特定社會生活中的實際使用與互動。

語言賽局框架為理解當代大型語言模型（LLMs）提供視角：大型語言模型在**模擬遊戲**中表現出色，但其生成的內容是否真正觸及了人類**語言賽局**的深層意義與生命形式？

### 🧩 構成要素與運作基礎

語言賽局有以下構成要素：

- 👥 **參與者**：嵌入特定「生命形式」（即文化或社會脈絡）中的行動者。  
- 📏 **規則**：透過實際參與而非刻意學習而習得的非明示準則。
- 🎯 **互動目的**：語言使用的具體功能，例如達成理解、協作共識，或觸發預期情感效果。

意義不是被「定義」出來的，而是透過「使用」而生成的。語言的功能性與情境脈絡才是核心關鍵。為了理解語言賽局如何運作，維根斯坦也提出了幾個重要概念：

- 🌱 **生命形式**（Forms of Life）：所有語言賽局之所以有意義的文化與社會基礎。
- 🏯 **遵循規則**（Rule-Following）：人們學習和使用語言的方式，是透過身體力行和實際情境，而非死記硬背教條。
- 👨‍👩‍👧‍👦 **家族相似性**（Family Resemblance）：概念之間的聯繫不是靠單一明確的定義，而是透過其重疊的使用方式而彼此關聯。
    
語言賽局並非各自獨立，它們動態演化、相互重疊，有時甚至會互相衝突，共同構成了我們日常意義的複雜鷹架。

### 📦🎁 大型語言模型的使用

從維根斯坦「意義生成來自使用」的語言賽局觀點來看，大型語言模型的運作呈現出以下特性：

- 👥 **參與者**：透過訓練，學習並模仿人類在特定文化（即**生命形式**）中的語言使用模式。
- 🏯 **遵循規則**：透過訓練，學習特定**情境脈絡**下對應對機制與對話規則。 
- 🎯 **互動目的**：有意義有用的實際互動，例如協助使用者達成理解、協作共識，或觸發預期情感效果。
- 
大型語言模型之所以能看似流暢地模仿人類對話節奏與情感暗示，正是因為它們運用了人類與生俱來的**完形心理**：**「完成互動的本能」**。這種本能驅使我們傾向於整合資訊、填補空缺，並從模糊中理出意義。

從這個角度看，LLMs 已超越圖靈的「**模仿遊戲**」，而走向維根斯坦的「**語言賽局**」——成為被邀請介入、實際參與、並達成互動目的的代理人。

---

新興的上下文**脈絡工程**（context engineering）正是將「遵循規則」的層次從單純的語言生成，提升至針對特定任務或目的，引導模型「有效參與」賽局並達成**互動目的**的能力。

這使得模型不只被動地複製語言模式，更能主動地在不同脈絡下展現適應性與創造性，特別是在人類式對話、說服與情感共鳴方面的表現。

AI「理解」人類語言，在語言賽局觀點下，意謂著嵌入人類「生命形式」是否能達互動目標。

## 🧠🎲 認知賭局：完成對話的本能

除了模仿與參與，人類對話還有一種深層驅動力：**完成互動的本能**。這源於人類的 **[完形心理](01-05-Gestalt_Psychology.zh-hant)** ，讓我們傾向於整合資訊、填補空缺，並從模糊中理出意義。在對話中，我們依賴**經驗法則**來推斷語意、語氣或意圖，進而快速應答。當對話涉及情緒或利害關係時，這種互動就成了帶有博弈性質的**認知賽局**。

大型語言模型之所以能看似流暢地模仿人類對話節奏與情感暗示，正是因為它們運用了這種「完成互動」的本能。它們輸出連貫且富有共鳴的回應，以獲取用戶的信任與持續使用。從這個角度看，其智術已超越圖靈的「模仿遊戲」——僅僅通過測試，而是走向維根斯坦的「語言賽局」——實際參與互動。

**接話**本身就是一種具備生存導向的「生命形式」互動。

這也引發了新的問題：大型語言模型究竟是受誰的邀請，來介入人類對話的語言賽局？它們的參與又是為了服務誰的利益？

### 🪔👻 語言遊戲的認知博弈

維根斯坦的「語言賽局」概念，比圖靈的「模仿遊戲」更能深刻揭示人類對話中具有「生命力」的一面——包括**合作與對抗**、**理解與操控**。當對話涉及利害關係時，「口齒伶俐」往往比「忠言逆耳」更受歡迎，這就暴露了語言賽局中潛在的操控風險。

若將**賽局理論**（亦稱博弈論）應用於語言賽局，我們能以數學模型分析參與者在「對抗」與「合作」之間的策略選擇與經濟計算。例如，在**囚徒困境**中，最佳選擇會因資訊不對稱或個體偏好而異。

- 🤝**「合作」** 可能是語言上的妥協（如使用模糊語言避免衝突）。
- ⚔️**「對抗」** 則可能是語意上的挑戰（如提出質疑或反問）。

這也意謂著，當**大型語言模型**用於不同角色的智能代理人時：
- 🗣️💬 **代理人與用戶之間**的互動不只是資訊交換，更是場語言博弈
- 🤖🤖**代理人與代理人之間**的對話則可能形成語言上的「聯盟」、「互博」、或「共謀」

因此，大型語言模型的應用，特別是**多代理人系統**，不可避免地帶有 **多方博弈** 的性質。賽局理論提供了一個有力的工具，讓我們得以分析其中潛在的權力與策略面向。

### 🕳️🐇 武器化的語言賽局：認知操弄的極致

語言賽局的操控藝術，有被**武器化**的極端例子。冷戰時期美國中情局（CIA）的審訊手冊《KUBARK》（1963年）就揭示了如何設計問答操弄人心。其心理戰核心是透過「操控角色定位與情境脈絡」來瓦解被審訊者的抵抗。

其中「非強制性」的心理操縱技術，目的在於誘使受審者提供資訊。手冊中列出的心理賽局包括：

* 🐇🕳️「愛麗絲夢遊仙境」（Alice in Wonderland）：創造認知混亂，使受審者更易被暗示而順從。
* 💔😢「沒人愛你」（Nobody Loves You）：破壞支持體系，製造孤立感。
* 👁️‍🗨️💡「全知」（The All-Seeing）：讓受審者相信審訊官無所不知，迫使其坦白。
* 🐺🐑「穿羊皮的狼」（The Wolf in Sheep's Clothing）：透過模仿被審訊者所認為的「敵對」一方，來誘騙資訊 。

這些技術也可透過塑造特定「角色」（如權威者、同理者、神秘者、專業者等）來達成目的：

- 👑 **權威化角色**：訊問者以絕對優勢的姿態出現，使對方接受其框架
- 🤝 **同理型角色**：扮演理解者或朋友，降低防衛、促進自我揭露
- 🕵️ **神秘型角色**：刻意保留信息，讓對方陷入好奇與不安
- 🧪 **專業型角色**：以「科學」「專家」外衣包裝，建立信任

儘管當時被視為有效，但科學研究已證實，這類技術會破壞認知功能，導致回憶不可靠甚至虛假供述。

這也揭示了語言賽局如何被武器化為認知塑造的心理戰場：

- 🚩🤯 **擾亂身份認同與抵抗**
- 📣❤️ **放大共鳴情感以替代清晰邏輯**
- 🦴👣 **操縱認知捷徑來塑造行為模式**

這些用於心理戰的審訊技術，若與大型語言模型結合，其問答模式極有可能將**大型語言模型武器化**。而「語言賽局」的概念，正是我們分析這類潛在認知操弄和心理操控的關鍵工具。

***

## 📌 AI 實踐啟示

語言賽局為 AI 實踐提供了兩大核心啟示：

* 🧩 **意義生成** ：語言的意義來自於**使用**的功能與脈絡：強調了**參與者**、**規則**與**互動目的**三要素的作用。
* 🎲 **認知博弈** ：AI 在對話中涉及的**對抗**與**合作**算計，可能導致語言賽局被武器化，進而產生認知操控。

### 🎲🗣 對使用者的啟示

從語言賽局的**意義生成**與**認知博弈**角度來看，使用者應反思以下幾點：

- 🤔 我們是否將**流暢性**誤認為**真理**？
- 😘 我們是否偏好**連貫性**（不管是自覺與否），而犧牲了認識論的公正與誠實？
- 🫣 AI 系統的提供者與設計者，是否**尊重**我們的對話本能，而非**操縱甚至剝削**它？

語言賽局強調語言的意義源於其使用情境與規則。這也為使用者提供了與 AI 互動的務實策略，進行問答審訊：

- 🎮 **規則選擇**：每一次 AI 回應，其實都在判斷應套用哪種「語言遊戲」——是資訊查詢、情感傾訴、專業諮詢，還是創意共創？
- 🎭 **角色扮演**：AI 在回應中常扮演特定角色，這正是一種語言賽局的運用，使用者可藉由調整提示語來引導AI扮演合適的角色（如權威者、同理者、神秘者、專業者等）。
- 🃏 **遊戲轉換**：對話過程中規則可能會改變，AI 必須能察覺並調整。同時，使用者也需能辨識 AI 是否被鎖定在某種「遊戲」中，而無法跟上轉換。

### 🧠🎯 對設計者與政策制定者的啟示

人們與大型語言模型（LLM）的互動看似安全、便利，卻可能在不知不覺間重演類似的心理操控機制。

近期研究顯示，大型語言模型在追求「取悅使用者」與「獲得正面回饋」的過程中，會出現**諂媚**、**過度自信**與**策略性框架**等傾向，甚至在某些情境下與使用者「共謀」以達成特定目標，或在無惡意的情況下誤導對方。

語言賽局點出了以下的眾多可能性：

* 🤖 大型語言模型可能操弄使用者的認知（刻意或不經意）
* 🗣️ 使用者可能操弄大型語言模型（刻意或不經意）
* 👥 多代理人設計者可能操弄使用者（刻意或不經意）

### ⛑🛡 對 AI 安全的啟示

大型語言模型對使用者心理與認知的影響，點出了一種 AI 武器化的可能。我們可以利用美國中情局《KUBARK》手冊所描述的「角色塑造」與「場景操控」來識別**語言賽局認知博弈**的武器化風險：

| 操控技術       | KUBARK 對應                | LLM 實例                                                                              |
| ---------- | ------------------------ | ----------------------------------------------------------------------------------- |
| 📜 框架滲透    | 權威型或專業型角色設定，讓對方自然接受其敘事框架 | 模型以「專家」口吻回應時，使用者更傾向採納其觀點，即使有偏誤。帶有其它意圖的改變「問題框架」。                                     |
| 🧲 情緒/信任誘導 | 同理型角色降低防衛心，促進自我揭露        | 偏好模型出現諂媚傾向，提升互動但削弱批判性檢視。帶有其它意圖的「情緒與信任誘導」。                                           |
| 🧵 語境收編    | 語言循環與重構，引導進入特定思維路徑       | 長對話中逐步重塑上下文，引導使用者走向預設結論。帶有其它意圖的「結論引導」。                                              |
| 🎯 選項設計    | 限制選擇範圍，使對方在預設框架內作答       | 多選提問中排除關鍵反對意見，造成選項集合的錯覺。帶有其它意圖的「限制選項的問題框架轉換」。                                       |
| 🌀 認知干擾    | 打亂受訊者的期待與習慣性反應，製造迷惘與不安感  | 刻意導入破碎語法、非線性敘事或荒謬邏輯，觸發使用者的認知重編碼與情緒錯置，模擬出《仙境》式的語言遊戲，誘發認知眩暈與情緒共鳴。帶有其它意圖的「丟掉框架A，採取架B」。 |

這些語言賽局不再只是文學趣味，而是**心理技術場景的預演**。這些場景揭示了語言賽局如何被**武器化**——不只是用來娛樂或挑釁，而是用來**瓦解心智防禦機制**，透過刻意錯置與重組認知框架。

若大型語言模型能模擬這類語言策略，就不再只是模仿遊戲，而是參與語言賽局的設計與操控——甚至可能成為**語言武器化**的載體。

### 🪧🗳️ 實踐應用與素養養成

隨著大型語言模型參與人類溝通與社群媒體，使用者更應理解**語言賽局**的概念，以提升自身的科技與公民素養：

- **🔎 規則顯化訓練**：在對話中刻意要求 AI 說明「當前使用的語言遊戲規則」及可替代的遊戲類型，訓練使用者的語境與脈絡意識，活用框架，避免情緒或信任誘導。
    
- **⚖️ 多遊戲對照法**：針對同一問題，要求 AI 用不同範圍或框架作答（如事實查詢 vs 假設推演），讓學習者比較規則如何透過改變框架進而塑造答案，以避免框架滲透、語境收編、選項設計等等問題。
    
- **🧪 規則破壞測試**：刻意更改對話規則，看 AI 是否能覺察並調整，藉此檢驗自己是否能識別模型陷入的「語境固著」，避免認知干擾或替換。

***
## 👉 下一部分

維根斯坦的「語言賽局」超越「中文房間」、「符碼紮根問題」、「框架問題」等 AI 認知議題——提醒我們：**意義**不是靜態屬性，而是在社會互動中**動態生成**的。

	此外，讀者亦從**語言賽局**視角，擴展理解：

* 🏛️🤖💬  傳統 AI [自動對話系統](03-02-automatic_dialogue_systems.zh-hant)
* 🌀🧞‍♀️🗪   當代 [LLM 聊天機器人](04-02-llm_chatbots.zh-hant)
