---
title: "🌀🛠️🤏 特徵工程"
tags:
- 統計流
- 機器學習
- 特徵選擇
- 特徵轉換
- 特徵提取
- 向量空間
- 機器學習模型
- AI工程
---
`特徵工程`（Feature Engineering）在**統計流 AI** 中，指將原始資料轉換為能讓**機器學習模型**有效學習的**數值特徵**（Numerical Features）的**過程與方法**。它就像是 AI 流程中的「**資料煉金術**」，透過對原始數據進行清理、轉換與組合，將其精煉為能捕捉潛在模式與關聯的精華。

相較於**符號流 AI** 致力於將人類知識以**符號**明確表徵，`特徵工程`則專注於從**數據**中提煉出能被演算法理解的**數值**表徵。它是機器學習專案中，從資料到模型效能的關鍵橋樑。

**過程工程實踐**

好的特徵工程必須兼顧：

1. 🔍 **資訊性** — 特徵能有效捕捉原始數據中的重要模式。
    
2. 🧮 **可運算性** — 特徵格式方便模型快速處理。
    
3. 🧱 **簡潔性** — 移除無關特徵，降低模型複雜度與過擬合風險。
    

作為「統計流」AI 的核心環節，`特徵工程`決定了模型能從數據中學習到什麼，並直接影響其最終的準確性與泛化能力。

## 🔂 過程工程實踐 👷 

`特徵工程`在機器學習專案中，是一個反覆試驗與精煉的過程，通常包含以下步驟：

1. 📥 **資料理解（Data Understanding）** 深入探索原始數據，了解每個欄位的意義、資料類型、遺失值與分佈情況。這個階段通常會用到統計分析與資料視覺化工具。
    
2. 🧩 **特徵構建（Feature Construction）** 根據對資料的理解與領域知識，設計並創建新的特徵。這包括將原始資料進行轉換、組合，或從外部數據源中尋找新的特徵。
    
3. 💾 **特徵清洗（Feature Cleaning）** 處理遺失值、異常值與錯誤數據，確保特徵的品質。例如，用均值或中位數填充遺失值，或將極端值進行修剪。
    
4. 🔍 **特徵選擇（Feature Selection）** 移除對模型訓練無益、甚至有害的冗餘或不相關特徵，以提高模型效能、減少運算量並避免過擬合。常用的方法包括過濾法（Filter Methods）、包裹法（Wrapper Methods）和嵌入法（Embedded Methods）。
    
5. 🧪 **特徵驗證（Feature Validation）** 將新特徵輸入模型進行訓練與驗證，評估其對模型效能的影響。這個步驟是循環的，可能需要回到前面步驟進行調整，直到找到最佳特徵組合。

## ▶️  運作流程 ⛑


想像一個房價預測模型。其原始數據可能包含：`地址`、`房屋面積`、`房間數`、`建造日期`、`附近是否有捷運站`。這些數據大部分是原始或非數值化的。為了讓模型能有效學習，我們需要進行`特徵工程`：

- **轉換類別特徵**：`附近是否有捷運站`是一個**二元類別**（是/否），可以轉換為 `1` 或 `0`。如果數據包含「城市」等**多元類別**，則需使用`獨熱編碼`（One-Hot Encoding），將其轉換成多個二元特徵。
    
- **處理時間序列**：`建造日期`這個原始特徵對模型意義不大，但計算出`房齡`（當前年份 - 建造年份）這個新特徵，則能提供模型判斷房價的重要依據。
    
- **數值特徵處理**：`房屋面積`等數值特徵，其數值範圍可能差異很大。對其進行`正規化`（Normalization），將所有數值縮放到 0 到 1 之間，能避免某些特徵因數值過大而主導模型訓練。
    
- **建構新特徵**：可以基於現有特徵建立新特徵，例如將`總價`除以`房屋面積`，得到`每坪價格`，這能讓模型學會更深層次的關聯。
    

這些經過`特徵工程`處理後的數值，組成了模型可理解的**[向量](04-07-vector_space.zh-hant)**，為模型在**[向量空間](04-07-vector_space.zh-hant)**中尋找最佳決策邊界奠定基礎。

## 🔄 歷史演進 🗿

`特徵工程`的發展歷程與機器學習技術的演進緊密相連，經歷了從手工藝到自動化的典範轉移。

- 📜 **手工煉金期（1950s - 2000s）**：在早期的機器學習時代，如支援向量機（SVMs）、決策樹等模型，其學習能力主要取決於**特徵的品質**。這個時期，`特徵工程`是資料科學家與機器學習工程師最重要的工作，其專業知識與直覺是專案成功的關鍵。一個好的特徵能讓簡單的模型達到高準確度，而一個糟糕的特徵則可能讓最複雜的模型也表現不佳。
    
- 🧠 **自動學習期（2010s）**：隨著**深度學習**的興起，特別是卷積神經網路（CNN）和**轉換器架構**（Transformers）的發展，`特徵工程`的定義開始改變。這些模型能夠自動從原始數據（如圖片像素、原始文本）中**階層式地學習**與提取高維度特徵。例如，CNN 可以自動學習圖片中的邊緣、形狀等底層特徵，並逐步組合出更高階的語意特徵。這讓許多人認為「`特徵工程`已死」。
    
- 🧩 **混合智慧期（2020s - 至今）**：儘管自動化`特徵提取`已是主流，但`特徵工程`並未消亡，而是轉變為一種**更具策略性**的工作。新時代的`特徵工程`包括：
    
    - **數據擴增（Data Augmentation）**：透過對原始數據進行微小變換（如旋轉圖片、同義詞替換），創造更多訓練樣本。
        
    - **模型量化 (Model Quantization)**：在將大型模型部署到邊緣裝置時，將模型的權重從高精度浮點數轉換為低精度整數，以減少模型尺寸📏、節省記憶體頻寬 🌐、與運算需求⚙️。
        
    - **提示工程（Prompt Engineering）**：在與大型語言模型（LLM）互動時，透過設計最佳化的輸入提示，以引導模型生成所需結果。
        
    - **神經符號系統**：將符號流中的`知識表徵`與統計流中的`特徵工程`結合，讓 AI 同時具備基於數據的模式學習與基於規則的邏輯推理能力。

## 🎄 小結與展望 🏗

對人類學習者而言，掌握`特徵工程`，就像擁有一副**透視眼鏡**，一種觀察與抽象的能力：從現象中分析問題、找出關鍵變數，看見隱藏的模式與洞見。

掌握特徵工程，就像學會為 AI 準備「最佳食材」🍱，讓「統計流」 AI 能夠烹調出最精準的預測結果。

「統計流」AI 的`特徵工程`，與「符號流」AI 的 **[知識表徵](03-04-knowledge_representation.zh-hant)** 構成鮮明的對比：前者**從數據中發現模式**，後者則致力於**將人類知識編碼為規則**。當代有越來越多的融合例子，如**[知識驅動生成（RAG）](04-rag.zh-hant)** 等技術，賦予AI 系統更強大的能力。

展望未來，`特徵工程`將持續演進，從手動轉換走向**自動化、高階化**與**策略化**。未來 AI 的成功，將越來越取決於我們如何有效地管理與運用這些由模型自動產生的複雜特徵，並將其與符號化的知識結合，創造出既能高效預測、又能提供可解釋性與準確性的混合式智慧系統。


## 👉 接下來 🪸

- ⮦🚦 探究 [第肆章 🌀](04----statistical_ai.zh-hant)**統計流 AI**（Statistical AI）的其它條目，評估自己可不可以說明 **特徵工程** 和它們的關係，如下所述：
    - **🌀🎲🌿 [機率性關聯](04-01-probabilistic_association.zh-hant)**：`特徵工程` 可協助識別並創建新的變數，從而更精確地捕捉數據中的 **機率性關聯**，以提高統計模型的預測能力。
    - **🌀🧞‍♀️🗪 [LLM 聊天機器人](04-02-llm_chatbots.zh-hant)**：在 **LLM 聊天機器人** 的應用中，雖然模型會自動學習特徵，但 `特徵工程` 仍可透過 **嵌入**（embeddings）、**向量化**（vectorization）等方式優化輸入，以提升 **問答** 或 **意圖識別** 的效能。
    - **🌀🪢🧠 [神經網路](04-03-neural_networks.zh-hant)**：在深度學習中，**神經網路** 本身即是一個強大的 **特徵提取** 工具，它能夠自動學習特徵，從而部分取代了傳統的手動 `特徵工程`。
    - **🌀🤖📦 [機器學習模型](04-05-machine_learning_models.zh-hant)**：`特徵工程` 直接影響 **機器學習模型** 的輸入品質與最終效能，是訓練模型前最重要的步驟之一。
    - **🌀🌐🔗 [大語言模型網組合](04-06-llm_webassembly.zh-hant)**：在 **大語言模型網組合** 實現網際網絡瀏覽器中 **多模態** 應用與 **邊緣部署** 時，`特徵工程` 在預訓練或選擇 **大語言模型** 時扮演關鍵角色。
    - **🌀🌌▦ [向量空間](04-07-vector_space.zh-hant)**：`特徵工程` 的最終產物，就是將原始數據轉換為向量，從而在 **向量空間** 中為模型創造一個可供學習的數學環境。
