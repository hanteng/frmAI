---
tags: 
  - 複雜即時策略
  - 非完全資訊博弈 
  - 多智能體博弈 
  - 團體對抗博弈 
  - 強化學習 
  - 深度學習 
  - OpenAI
---
# 🧙‍♂🥷 OpenAI Five🏆 {#sec-openai-five}

`OpenAI Five` 是由非營利人工智慧研究機構 **OpenAI** 所開發，這個 AI 團隊在多人線上競技遊戲 **《Dota 2》** 中，展現出超越人類頂尖職業選手的團隊協作與戰術實力。OpenAI Five 的成就，標誌著 AI 在處理**多智能體博弈**（Multi-Agent Game）和**複雜即時策略**（Real-Time Strategy, RTS）環境中的重要里程碑。

## 🖼️ 背景資訊

### 🎮 關於《Dota 2》

**《Dota 2》**（Defense of the Ancients 2）是一款由 Valve 公司開發的免費多人線上戰術競技遊戲（MOBA）。遊戲特色是兩支各由五名玩家組成的隊伍，在地圖上進行對抗。遊戲的複雜性來自於龐大的英雄技能組合、地圖動態變化以及**非完全資訊**（部分地圖視野被遮蔽）等因素。

### ⌬ 關於 OpenAI

**OpenAI** 成立於 2015 年，最初作為一家非營利組織，目標是發展通用人工智慧（AGI）造福全人類。該機構在深度學習和強化學習領域取得了許多開創性成果，例如 GPT 系列語言模型、DALL-E 圖像生成模型，以及在博弈 AI 上的突破，包括這個 Dota 2 專案。

---

## 🏆 博弈挑戰

《Dota 2》的博弈挑戰遠超單人對戰遊戲，它不僅要求 AI 在單一角色上做出最佳決策，更需要協調五個獨立智能體的行動，以實現共同的團隊目標。具體挑戰有：

- **複雜的多智能體協作**：五個 AI 必須像一個團隊一樣運作，共同規劃策略、執行戰術，並即時應對敵方行動；
- **長期的時間尺度**：一局遊戲可能持續 45 分鐘，AI 必須考量長期目標（例如摧毀敵方基地），而非僅僅追求短期收益（例如擊殺敵方英雄）；
- **非完全資訊**：部分地圖對雙方玩家而言是不可見的（戰爭迷霧），這要求 AI 必須學會**預測**、**推理**與**風險評估**。
- **巨大的動作空間**：每個英雄都有數十種潛在行動（移動、釋放技能、購買道具），且需要在毫秒級別內做出決策。

**因此，OpenAI Five 的挑戰核心是將複雜的即時策略、多智能體協作、和不完全資訊結合在一起。**

## 📜 博弈歷史

OpenAI Five 的成功，是透過逐步擴大規模和複雜性達成的。

- **22017年**：OpenAI 開發出一個能進行《Dota 2》**單挑賽**的 AI，並在國際邀請賽（The International）中擊敗了世界頂級職業選手 Dendi，展現了其在單兵作戰方面的實力；
- **2018年**：OpenAI 發表了 **OpenAI Five**，一個由五個 AI 智能體組成的團隊，能在 5v5 的完整遊戲模式中進行對抗。該團隊在多場公開賽中擊敗了人類業餘玩家；
- **2018年**：OpenAI Five 在國際邀請賽上與人類職業選手團隊進行表演賽，最終表現出與人類頂尖選手相當的實力，證明了**大規模強化學習**在團隊協作方面的可行性。

## ✅ 克服難點方式

OpenAI Five 透過極為**大規模的強化學習**和**自我博弈**，克服了多智能體、即時策略和長時尺度的挑戰。

1.  **無限自我博弈（Self-Play）**：五個 AI 智能體在虛擬環境中，以極高的速度進行了數百萬局的自我對戰（每天相當於數百年的人類遊戲時長）。這種方式讓它們在沒有人類數據的情況下，從零開始自主學習和發展出**超越人類經驗**的團隊策略。
2.  **獎勵函數設計（Reward Shaping）**：工程師精心設計了**獎勵函數**，以鼓勵 AI 做出對團隊有利的行為，例如擊殺敵方英雄、推塔、以及最終摧毀基地等。這引導 AI 在複雜的長期目標下，做出最佳的短期決策。
3.  **單一策略網絡（Single Policy Network）**：OpenAI Five 採用了一個單一的 **循環神經網路（LSTM）** 來處理五個智能體的行動，這使得智能體之間能自然地共享資訊和協調目標，是實現團隊合作的關鍵。

## 🔑 關鍵技術

OpenAI Five 的核心是利用**近端策略優化**和**循環神經網路**來處理即時、長時序和多智能體的複雜性。

* **大規模近端策略優化（Proximal Policy Optimization, PPO）**：這是一種高效的**策略梯度**強化學習算法，用於優化 AI 的行動策略。OpenAI Five 利用 PPO 能夠在數百個 GPU 上進行**數千年的遊戲時間**模擬，實現極致的訓練規模。
* **循環神經網路 (LSTM) 記憶**：每個 AI 智能體都使用 **LSTM**（長短期記憶）網絡來處理即時的狀態輸入，使其能夠整合長時間的資訊（例如過去的戰鬥、地圖視野的變化），從而做出具備**長期規劃性**的決策。
* **參數共享 (Parameter Sharing)**：雖然有五個獨立的智能體，但它們共享同一個神經網路模型的**權重**，這極大地提高了學習效率，並促進了五個角色之間形成統一且高效的團隊策略。

## 💡 AI 應用啟發

OpenAI Five 的案例，展示了 AI 在複雜**多智能體**和**非完全資訊**的環境下，能透過自我學習掌握高度抽象的策略，並實現精確協調。

- **🎯 問題意識**：適用於 **需要多個智能體協同合作** 以解決複雜、動態任務的場景，例如協同機器人操作、無人機編隊或戰術指揮。
- **🗺️ 建構資源**：能用 **高維度數據** 和**即時動態**來表示的團隊互動環境；關鍵在於能夠建立**高效能的模擬器**來支持大規模的自我博弈。
- **⚡ 智能加值**：AI 能夠在沒有人類專家數據的情況下，從零開始發展出**超越人類經驗**的團隊策略，顯示出強化學習在解決複雜協作問題上的潛力。
- **🏭 佈署條件**：適合在**多代理人**和**即時決策**的環境中部署，例如物流管理、工業自動化或網路安全防禦。

### 對「博弈派」AI 的核心貢獻

* **征服複雜即時多智能體博弈**：首次證明 AI 可以在具有即時行動、長時尺度、和大量變數的 **5v5 多智能體團體對抗**環境中擊敗人類頂尖玩家，將博弈 AI 的邊界推向即時策略領域。
* **強化學習實現團隊協作**：展示了透過 **PPO** 和**參數共享**的強化學習方法，可以讓多個獨立智能體學會**去中心化**（Decentralized）但**協調一致**的團隊策略，這對複雜的軍事或商業決策有巨大啟發。
* **長時序規劃的實證**：由於遊戲時長長達數十分鐘，AI 必須學會犧牲短期目標（如單次擊殺）來實現長期策略（如資源積累、推塔時機），體現了其優秀的**長時序決策能力**。

### 對「具身派」AI 的啟發

* **多機器人協作的藍圖**：OpenAI Five 的架構是設計**多具身智能體系統**的藍圖，例如多輛無人車在擁擠道路上的協調、或多架無人機的編隊飛行與共同偵察。
* **即時感知與行動**：在毫秒級別的即時策略環境中做出複雜決策，與具身 AI 需要即時處理感測器數據並精確控制物理系統的需求高度相似。
* **從模擬到現實的橋樑**：OpenAI Five 的訓練高度依賴其高效率的虛擬環境。這鼓勵具身 AI 領域開發更準確、更大規模的**模擬器**，以利於在安全且可控的環境中進行大規模強化學習。

***

## 👉 下一部分

在理解 **[OpenAI Five](07-05-openai_five.zh-hant.md)** 在複雜團隊博弈中的啟發後，接下來探討 **[狼人殺 AI](07-06-werewolf_ai.zh-hant.md)** 在涉及**推理**與**欺騙**的博弈中的啟發。